# 开发日志：修复增量入库副作用（重复/漏消息/私聊聚合割裂）

日期：2026-01-18  
模块：AI 向量入库（RAG ingest）/ Chat 会话读取与聚合  
相关改动文件（拟合并）：  
- internal\modules\ai\infrastructure\queue\ingest_consumer_worker.go  
- internal\modules\ai\infrastructure\pipeline\ingest_pipeline.go  
- internal\modules\ai\infrastructure\reader\chat_session_reader.go  

---

## 1. 背景

当前的“最小可用增量入库”策略是：当聊天消息到达时，异步触发一次 ingest 事件；consumer 侧为了避免“刚发的消息因为并发/时钟/延迟没读到”，会用 `since = msg.CreatedAt - 5s` 作为保险窗口，并且每次只读“最新 Page=1 的 50 条”，把读到的文本消息送进 pipeline 做 chunk + embed + upsert。

该策略短期能让数据快速进向量库，但在真实线上高频聊天下，会引发明显的召回与对话质量问题。

---

## 2. 问题

### 2.1 可能重复入库（重叠窗口导致同批消息反复进入 pipeline）
- 多个 ingest 事件的 `since=CreatedAt-5s` 窗口会重叠（尤其是 5 秒内连续发多条）。
- 每次又固定读“最新 50”，容易把同一批消息重复送入 pipeline。
- 如果 chunkKey 依赖“批次索引/聚合切分结果”，在窗口内容变化、合并策略变化时 chunkKey 不稳定，重复向量更难被幂等挡住。

### 2.2 高峰期可能漏消息（只读 Page=1）
- 群聊高峰时，5 秒内文本消息量可能 > 50。
- 只读 Page=1 会漏掉 Page=2..n 的消息；因为没有继续翻页，也没有 per-source 的 last_cursor 机制。

### 2.3 私聊聚合结构性割裂（SessionId 不可靠）
- 现有聚合器 `ChatTurnMerger.Merge` 会按 `SessionId` 分组。
- 私聊落库时 `Message.SessionId` 填的是“发送方 session uuid”，读历史时同一个私聊会混入双方消息，导致出现两个不同 SessionId，从而被聚合拆成两段，各自缺对方上下文，语义连贯性下降。
- 群聊里 SessionId 为空串也说明：SessionId 并不是可靠的“对话范围 key”。

---

## 3. 目标

1. 在不引入“last_ingested_cursor 表/字段”的前提下，降低漏消息风险：对于非回填任务，consumer 侧支持翻页读取，直到满足 stop 条件。  
2. 强化幂等：chunkKey 由“消息自身稳定标识（message uuid）”驱动，避免因窗口/聚合变化导致的重复向量。  
3. 修复私聊聚合割裂：chat 消息的 ingest 不再依赖 SessionId 分组聚合，保证上下文按时间顺序连贯。  
4. 保持与现有架构兼容：尽量复用现有 reader/repo/pipeline 结构。

---

## 4. 修改概览

### 4.1 consumer：非回填任务增加翻页，使用“原始消息页”控制 stop 条件，避免漏消息
- 变更点：internal\modules\ai\infrastructure\queue\ingest_consumer_worker.go
- 核心思路：
  - 对非 backfill（实时增量）事件，不再只读 Page=1，而是最多翻页到 `maxPages`（例如 50 页）。
  - 为了避免“过滤后的页面为空导致提前 stop”（例如最近一页全是非文本/系统消息），stop 条件基于“原始消息页（未按 since/类型过滤）”来判断是否继续翻页。
  - 过滤逻辑（文本、since、until）仍然应用于“送入 pipeline 的消息集合”，但不用于控制是否停止翻页。

### 4.2 pipeline：chat 类消息改为按 message uuid 生成稳定 chunkKey，并绕开 SessionId 聚合
- 变更点：internal\modules\ai\infrastructure\pipeline\ingest_pipeline.go
- 核心思路：
  - 对 `chat_private/chat_group`：不使用 `ChatTurnMerger.Merge`（避免 SessionId 拆分）。
  - 改为“逐条消息”按时间排序处理：每条 message 形成一个 unitKey（使用 `message.Uuid`），再对该 message 的文本做 chunk。
  - chunkKey 由 `tenant + sourceType + sourceKey + messageUuid(unitKey) + subIdx + contentHash` 构成（并做 sha256），确保同一条消息同一段 chunk 的 key 稳定。
  - 这样即使 consumer 因窗口重叠/翻页重复触发，也会在向量库 upsert 时自然幂等（同 key 覆盖/不重复插入）。

### 4.3 reader：补一个 ReadMessagesPage，提供“未过滤的原始分页消息”
- 变更点：internal\modules\ai\infrastructure\reader\chat_session_reader.go
- 核心思路：
  - 新增 `ReadMessagesPage(ctx, userID, session, page, pageSize)`：直接从 repo 取该会话该页消息，不做 since/type 等过滤。
  - consumer 使用它来判断：是否已经翻到足够老的页、是否还有更多页，从而避免“被过滤后空页”误判终止。

---

## 5. 结果（预期效果）

1. 重复入库显著降低：
- chunkKey 绑定 message uuid，与批次序号/聚合切分无关；窗口重叠导致的重复消费会被幂等挡住。

2. 漏消息风险降低：
- 非 backfill 情况支持翻页；高峰期 5 秒内超过 50 条也能继续向后读取更多页（上限由 maxPages 控制）。

3. 私聊上下文更连贯：
- chat ingest 绕开 SessionId 分组聚合，改为按消息时间排序逐条处理，避免私聊被拆成两段导致的上下文缺失。

---

## 6. 开发过程（按步骤记录）

1. 复盘现状与故障模式：
- 识别 “since=-5s + Page=1 + 50条” 在高峰时的漏消息风险。
- 识别 chunkKey 不稳定导致的幂等失效路径（窗口变化/聚合变化 -> chunkKey变化 -> 重复向量）。
- 识别私聊 `SessionId` 双方不同导致聚合拆分的结构性问题。

2. 设计约束下的方案选择：
- 不引入 last_cursor 的持久化结构（避免 schema/迁移成本）。
- 通过两类手段提高稳健性：
  - consumer 翻页：减少漏。
  - pipeline key 稳定：减少重复/增强幂等。

3. 分层落地：
- 先补 reader 的“原始分页读取能力”以支撑 consumer 的正确 stop 条件。
- 再改 consumer：把原“只读 Page=1”升级为“按页循环 + 原始页 stop + 过滤后累积”。
- 最后改 pipeline：chat 走 message uuid 驱动的 chunkKey，并绕开 SessionId 聚合。

4. 风险检查：
- 翻页增加 DB 压力：通过 maxPages 限制最坏情况。
- chunkKey 改动会改变向量库 key：属于行为变更，需结合向量库 upsert/删除策略评估（至少可保证从变更后开始不再扩大重复问题）。

---

## 7. 重点代码解析（关键逻辑）

### 7.1 consumer 翻页与 stop 条件：为什么要用“原始消息页”
典型坑：如果用“过滤后的消息”判断 stop，当最近一页全是非文本/系统消息时，过滤后为空，会误判“没有新消息”，从而停止翻页；但实际上下一页可能有大量文本消息（刚好都在窗口里），会导致漏消息。

解决：把 stop 条件绑定到“原始分页消息 raw（未过滤）”：
- raw 为空：说明没有更多消息，可停止。
- raw 最老消息时间 <= since：说明已经翻到窗口之外，可停止。
- 过滤后的 pageMsgs 为空：不代表可以停止，只代表这一页没有需要入库的消息，但仍应继续翻页。

### 7.2 pipeline chat：绕开 SessionId 聚合，逐条消息排序处理
私聊割裂的根因是 SessionId 在双方消息上不一致；把聊天 ingestion 的“对话范围 key”建立在 SessionId 上会天然不可靠。  
改为按 message 粒度处理：
- 先过滤掉非文本消息与空白内容。
- 按 `(CreatedAt, Uuid)` 排序，保证稳定顺序。
- 每条消息生成一个 unitKey = message.Uuid，chunkKey 绑定 unitKey，天然幂等。

### 7.3 chunkKey 设计：稳定性与幂等
chunkKey 推荐包含以下维度并做 hash：
- tenant：避免跨租户冲突
- sourceType/sourceKey：避免跨来源冲突（不同群/不同私聊）
- unitKey（message uuid）：稳定绑定到消息
- subIdx：同一条消息多个 chunk 的编号
- contentHash：当 chunk 内容改变时 key 跟着变化，避免错误覆盖

这样即使上游重复触发 ingest，也能保证相同 chunk 的 key 恒定，向量 upsert 不会膨胀重复数据。

---

## 8. 验证建议（手工/联调）

1. 重复触发验证：
- 在 5 秒内连续发送多条消息，触发多次 ingest。
- 检查向量库同一消息的向量条目数量：应不随触发次数增长（幂等）。

2. 高峰漏消息验证：
- 构造 5 秒内 > 50 条文本消息（群聊刷屏）。
- 检查是否仍能被 ingest：应能翻页覆盖到 Page=2..n（受 maxPages 上限影响）。

3. 私聊上下文验证：
- 私聊双方交替发言，检查入库 chunk 是否按时间顺序连续覆盖双方内容，不应出现“按 SessionId 分段”的断裂。

---

## 9. 后续可选优化（不在本次改动范围内）

- 引入 per-source last_ingested_cursor（时间或 message_id）作为长期稳健方案，减少翻页扫描成本。
- 对 backfill 与 realtime 统一为 cursor 语义，完善“补齐/重试”策略。
- 对向量库做历史 key 迁移或清理策略，避免旧 key 造成的遗留重复。