# 模块三：AI 微服务/小工具 - 超详细实施指南

## 第 6 部分：数据库迁移

> **文档版本**: v1.0  
> **创建日期**: 2026-02-09  
> **适用范围**: OmniLink 项目 AI 微服务模块数据持久化层  
> **依赖部分**: Part 1 插件系统, Domain 实体定义

---

## 📚 目录

1. [概述](#1-概述)
2. [数据库表结构设计](#2-数据库表结构设计)
3. [代码实现](#3-代码实现)
   - [3.1 GORM AutoMigrate 集成](#31-gorm-automigrate-集成)
   - [3.2 初始数据填充](#32-初始数据填充)
4. [SQL 参考脚本](#4-sql-参考脚本)
5. [执行步骤](#5-执行步骤)
6. [验证与测试](#6-验证与测试)
7. [回滚方案](#7-回滚方案)
8. [索引优化说明](#8-索引优化说明)

---

## 1. 概述

### 1.1 设计原则

**本次迁移遵循以下生产级原则**：

| 原则 | 实现方式 |
|------|----------|
| **幂等性** | GORM AutoMigrate 自动检测表是否存在，不存在才创建 |
| **向后兼容** | 新表独立，不修改现有表结构 |
| **性能优化** | 基于查询模式添加联合索引和单列索引 |
| **数据完整性** | NOT NULL 约束 + 默认值 + UNIQUE 约束 |
| **扩展性** | 使用 JSON 字段存储灵活配置（config_json, model_config_json） |
| **可观测性** | 日志表记录每次调用的完整上下文（延迟、Token、缓存命中） |

### 1.2 迁移涉及的表

| 表名 | 用途 | 估算容量 |
|------|------|----------|
| `ai_microservice_config` | 服务配置表（存储每种服务的模型配置、Prompt 模板） | ~10 行（静态配置） |
| `ai_microservice_call_log` | 调用日志表（性能分析、计费、审计） | 100W+/月（高频写入） |

---

## 2. 数据库表结构设计

### 2.1 表设计概览

#### 表 1: `ai_microservice_config` - 服务配置表

**设计目标**：
- 支持动态调整每种服务（input_prediction/polish/digest）的模型参数
- 无需重启即可修改 Prompt 模板、温度、最大 Token 等
- 支持热更新（后台定时从 DB 刷新配置）

**字段清单**：

| 字段名 | 类型 | 约束 | 索引 | 说明 |
|--------|------|------|------|------|
| `id` | BIGINT | PK, AUTO_INCREMENT | PRIMARY | 自增主键 |
| `service_type` | VARCHAR(50) | NOT NULL, UNIQUE | UNIQUE | 服务类型：`input_prediction`/`polish`/`digest` |
| `is_enabled` | TINYINT(1) | NOT NULL, DEFAULT 1 | - | 是否启用（0=禁用, 1=启用） |
| `config_json` | JSON | NOT NULL | - | 服务级配置（如 debounce_ms, max_input_chars） |
| `model_config_json` | JSON | NOT NULL | - | 模型配置（provider, model, api_key, temperature 等） |
| `prompt_template` | MEDIUMTEXT | - | - | Prompt 模板（支持占位符，如 `{{user_input}}`, `{{context}}`） |
| `created_at` | DATETIME | NOT NULL | - | 创建时间 |
| `updated_at` | DATETIME | NOT NULL | - | 更新时间 |

**JSON 字段结构示例**：

```json
// config_json 示例（input_prediction 服务）
{
  "debounce_ms": 500,
  "max_input_chars": 500,
  "context_messages": 10,
  "enable_cache": true,
  "cache_ttl": 300
}

// model_config_json 示例
{
  "provider": "volcengine_ark",
  "model": "doubao-lite-8k",
  "api_key": "env:DOUBAO_API_KEY",  // 支持从环境变量读取
  "base_url": "https://ark.cn-beijing.volces.com/api/v3",
  "temperature": 0.7,
  "max_tokens": 50,
  "timeout_seconds": 5
}
```

**索引设计**：
```sql
UNIQUE INDEX `idx_service_type` (`service_type`)  -- 确保每个服务类型唯一
```

---

#### 表 2: `ai_microservice_call_log` - 调用日志表

**设计目标**：
- 记录每次微服务调用的完整链路（输入、输出、延迟、Token、缓存命中）
- 支持按用户、服务类型、时间段聚合统计
- 为计费、性能分析、问题排查提供数据基础

**字段清单**：

| 字段名 | 类型 | 约束 | 索引 | 说明 |
|--------|------|------|------|------|
| `id` | BIGINT | PK, AUTO_INCREMENT | PRIMARY | 自增主键 |
| `request_id` | CHAR(20) | NOT NULL, UNIQUE | UNIQUE | 请求唯一 ID（雪花 ID 或 UUID） |
| `tenant_user_id` | CHAR(20) | NOT NULL | INDEX | 租户用户 ID（用于多租户隔离） |
| `service_type` | VARCHAR(50) | NOT NULL | INDEX | 服务类型 |
| `input_text` | MEDIUMTEXT | - | - | 用户输入文本 |
| `output_text` | MEDIUMTEXT | - | - | AI 生成结果 |
| `context_json` | JSON | - | - | 上下文信息（聊天历史、会话 ID 等） |
| `latency_ms` | INT | - | - | 请求延迟（毫秒） |
| `tokens_used` | INT | - | - | 消耗 Token 数（用于计费） |
| `is_cached` | TINYINT(1) | DEFAULT 0 | - | 是否命中缓存（0=未命中, 1=命中） |
| `error_msg` | TEXT | - | - | 错误信息（成功时为空） |
| `created_at` | DATETIME | NOT NULL | INDEX | 创建时间 |

**索引设计**：
```sql
UNIQUE INDEX `idx_request_id` (`request_id`)                    -- 防止重复记录
INDEX `idx_tenant_user_id` (`tenant_user_id`)                   -- 按用户查询
INDEX `idx_service_type` (`service_type`)                       -- 按服务类型统计
INDEX `idx_created_at` (`created_at`)                           -- 按时间范围查询
INDEX `idx_tenant_service_time` (`tenant_user_id`, `service_type`, `created_at`)  -- 联合索引（用户+服务+时间聚合）
```

**存储空间估算**：

假设单条记录平均大小 = 2KB（input_text + output_text + context_json）
- 日调用量 10 万次 → 200MB/天 → 6GB/月
- 建议保留策略：**保留最近 90 天数据**，定期归档到对象存储

---

## 3. 代码实现

### 3.1 GORM AutoMigrate 集成

**文件路径**: `internal/initial/gorm.go`

#### 3.1.1 代码修改

在现有 `AutoMigrate` 调用中添加微服务模块的两个实体：

```go
package initial

import (
	"OmniLink/internal/config"
	aiAgent "OmniLink/internal/modules/ai/domain/agent"
	aiAssistant "OmniLink/internal/modules/ai/domain/assistant"
	aiJob "OmniLink/internal/modules/ai/domain/job"
	aiRag "OmniLink/internal/modules/ai/domain/rag"
	aiMicroservice "OmniLink/internal/modules/ai/domain/microservice"  // 新增导入
	chatEntity "OmniLink/internal/modules/chat/domain/entity"
	contactEntity "OmniLink/internal/modules/contact/domain/entity"
	userEntity "OmniLink/internal/modules/user/domain/entity"

	"OmniLink/pkg/zlog"
	"fmt"
	"log"
	"os"
	"time"

	"gorm.io/driver/mysql"
	"gorm.io/gorm"
	"gorm.io/gorm/logger"
)

var GormDB *gorm.DB

func init() {
	conf := config.GetConfig()
	user := conf.MysqlConfig.User
	password := conf.MysqlConfig.Password
	host := conf.MysqlConfig.Host
	port := conf.MysqlConfig.Port
	appName := conf.AppName
	zlog.Info(fmt.Sprintf("mysql connecting: %s:%d/%s", host, port, appName))
	dsn := fmt.Sprintf("%s:%s@tcp(%s:%d)/%s?charset=utf8mb4&parseTime=True&loc=Local&timeout=5s&readTimeout=10s&writeTimeout=10s", user, password, host, port, appName)
	
	var err error
	gormLogger := logger.New(
		log.New(os.Stdout, "\r\n", log.LstdFlags),
		logger.Config{
			SlowThreshold:             time.Second,
			LogLevel:                  logger.Warn,
			IgnoreRecordNotFoundError: true,
			Colorful:                  false,
		},
	)
	GormDB, err = gorm.Open(mysql.Open(dsn), &gorm.Config{Logger: gormLogger})
	if err != nil {
		zlog.Fatal(err.Error())
	}

	// 自动迁移
	err = GormDB.AutoMigrate(
		&userEntity.UserInfo{},
		&contactEntity.UserContact{},
		&contactEntity.ContactApply{},
		&contactEntity.GroupInfo{},
		&chatEntity.Session{},
		&chatEntity.Message{},
		&chatEntity.MessageMention{},

		&aiRag.AIKnowledgeBase{},
		&aiRag.AIKnowledgeSource{},
		&aiRag.AIKnowledgeChunk{},
		&aiRag.AIVectorRecord{},
		&aiRag.AIIngestEvent{},
		&aiRag.AIBackfillJob{},

		&aiAssistant.AIAssistantSession{},
		&aiAssistant.AIAssistantMessage{},
		&aiAgent.AIAgent{},
		&aiJob.AIJobDef{},
		&aiJob.AIJobInst{},

		// 新增：AI 微服务模块实体
		&aiMicroservice.AIMicroserviceConfig{},
		&aiMicroservice.AIMicroserviceCallLog{},
	)
	// 自动迁移，如果没有建表，会自动创建对应的表
	if err != nil {
		zlog.Fatal(err.Error())
	}

	zlog.Info("Database migration completed successfully")
}
```

#### 3.1.2 代码解释

**第 9 行**：`aiMicroservice "OmniLink/internal/modules/ai/domain/microservice"`
- 导入微服务模块的 domain 实体包
- 使用别名 `aiMicroservice` 与其他 AI 模块保持命名一致性

**第 70-71 行**：添加 AutoMigrate 实体
```go
&aiMicroservice.AIMicroserviceConfig{},
&aiMicroservice.AIMicroserviceCallLog{},
```
- `&aiMicroservice.AIMicroserviceConfig{}`：配置表实体
- `&aiMicroservice.AIMicroserviceCallLog{}`：日志表实体
- GORM 会根据结构体的 `gorm` 标签自动生成 DDL：
  - 表名由 `TableName()` 方法指定
  - 字段类型、索引、约束由 `gorm` tag 定义
  - 若表已存在，AutoMigrate **仅添加缺失字段**，不会删除现有字段

**第 79 行**：添加成功日志（可选）
```go
zlog.Info("Database migration completed successfully")
```
- 便于启动时确认迁移已执行

---

### 3.2 初始数据填充

#### 3.2.1 填充脚本

**文件路径**: `internal/modules/ai/infrastructure/persistence/init_microservice_config.go`（新建）

```go
package persistence

import (
	"encoding/json"
	"OmniLink/internal/initial"
	"OmniLink/internal/modules/ai/domain/microservice"
	"OmniLink/pkg/zlog"
)

// InitMicroserviceDefaultConfig 初始化默认配置（首次启动时调用）
func InitMicroserviceDefaultConfig() error {
	db := initial.GormDB

	// 检查配置表是否已有数据
	var count int64
	if err := db.Model(&microservice.AIMicroserviceConfig{}).Count(&count).Error; err != nil {
		return err
	}

	// 已有配置，跳过初始化
	if count > 0 {
		zlog.Info("AI microservice config already initialized, skipping...")
		return nil
	}

	zlog.Info("Initializing default AI microservice configurations...")

	// 配置 1: input_prediction（智能输入预测）
	inputPredictConfig := map[string]interface{}{
		"debounce_ms":       500,
		"max_input_chars":   500,
		"context_messages":  10,
		"enable_cache":      true,
		"cache_ttl":         300, // 5分钟
		"stream_enabled":    true,
	}
	inputPredictModelConfig := map[string]interface{}{
		"provider":         "volcengine_ark",
		"model":            "doubao-lite-8k",
		"api_key":          "env:DOUBAO_API_KEY",
		"base_url":         "https://ark.cn-beijing.volces.com/api/v3",
		"temperature":      0.7,
		"max_tokens":       50,
		"timeout_seconds":  5,
	}
	inputPredictPrompt := `你是一个智能输入助手，根据用户当前输入和聊天上下文，预测用户可能想输入的后半句。

## 上下文（最近 {{context_count}} 条消息）：
{{context_messages}}

## 用户当前输入：
{{user_input}}

## 要求：
1. 预测应自然流畅，不超过 20 字
2. 避免重复用户已输入内容
3. 直接输出预测文本，不要解释
4. 若无法预测，输出空字符串`

	inputPredictConfigJSON, _ := json.Marshal(inputPredictConfig)
	inputPredictModelJSON, _ := json.Marshal(inputPredictModelConfig)

	configInput := &microservice.AIMicroserviceConfig{
		ServiceType:     "input_prediction",
		IsEnabled:       1,
		ConfigJson:      string(inputPredictConfigJSON),
		ModelConfigJson: string(inputPredictModelJSON),
		PromptTemplate:  inputPredictPrompt,
	}

	// 配置 2: polish（文本润色）
	polishConfig := map[string]interface{}{
		"max_input_chars": 1000,
		"enable_cache":    true,
		"cache_ttl":       1800, // 30分钟
		"max_options":     3,    // 最多返回3个润色选项
	}
	polishModelConfig := map[string]interface{}{
		"provider":        "volcengine_ark",
		"model":           "doubao-lite-8k",
		"api_key":         "env:DOUBAO_API_KEY",
		"base_url":        "https://ark.cn-beijing.volces.com/api/v3",
		"temperature":     0.8,
		"max_tokens":      200,
		"timeout_seconds": 10,
	}
	polishPrompt := `你是文本润色专家，根据用户原文和上下文，提供 2-3 种不同风格的改写建议。

## 上下文：
{{context_messages}}

## 用户原文：
{{user_input}}

## 要求：
1. 保持原意，仅调整表达风格
2. 输出 JSON 格式：{"options": [{"style": "更礼貌", "text": "..."}, {"style": "更直接", "text": "..."}]}
3. style 字段限定：更礼貌/更直接/更专业/更活泼/更正式/更委婉
4. 最多返回 3 个选项`

	polishConfigJSON, _ := json.Marshal(polishConfig)
	polishModelJSON, _ := json.Marshal(polishModelConfig)

	configPolish := &microservice.AIMicroserviceConfig{
		ServiceType:     "polish",
		IsEnabled:       1,
		ConfigJson:      string(polishConfigJSON),
		ModelConfigJson: string(polishModelJSON),
		PromptTemplate:  polishPrompt,
	}

	// 配置 3: digest（消息摘要）
	digestConfig := map[string]interface{}{
		"min_messages":    50,  // 触发阈值
		"max_messages":    200, // 最多处理200条消息
		"enable_cache":    true,
		"cache_ttl":       600, // 10分钟
		"summary_length":  "medium", // short/medium/long
	}
	digestModelConfig := map[string]interface{}{
		"provider":        "volcengine_ark",
		"model":           "doubao-pro-32k", // 使用长上下文模型
		"api_key":         "env:DOUBAO_API_KEY",
		"base_url":        "https://ark.cn-beijing.volces.com/api/v3",
		"temperature":     0.5, // 降低随机性，确保摘要准确
		"max_tokens":      500,
		"timeout_seconds": 15,
	}
	digestPrompt := `你是消息摘要专家，将群聊记录提炼为结构化摘要。

## 消息记录（最近 {{message_count}} 条）：
{{messages}}

## 要求：
1. 按主题分组，每个主题包含：话题、参与者、核心观点
2. 忽略无意义的闲聊（如"哈哈"、"在吗"）
3. 输出 Markdown 格式：
   - 主题1：[话题名称]
     - 参与者：@用户A、@用户B
     - 核心内容：...
   - 主题2：...
4. 总字数不超过 300 字`

	digestConfigJSON, _ := json.Marshal(digestConfig)
	digestModelJSON, _ := json.Marshal(digestModelConfig)

	configDigest := &microservice.AIMicroserviceConfig{
		ServiceType:     "digest",
		IsEnabled:       1,
		ConfigJson:      string(digestConfigJSON),
		ModelConfigJson: string(digestModelJSON),
		PromptTemplate:  digestPrompt,
	}

	// 批量插入
	configs := []*microservice.AIMicroserviceConfig{
		configInput,
		configPolish,
		configDigest,
	}

	result := db.Create(&configs)
	if result.Error != nil {
		zlog.Error("Failed to initialize microservice config: " + result.Error.Error())
		return result.Error
	}

	zlog.Info("Default AI microservice configurations initialized successfully")
	return nil
}
```

#### 3.2.2 代码解释（关键点）

**第 10-22 行**：幂等性检查
```go
var count int64
if err := db.Model(&microservice.AIMicroserviceConfig{}).Count(&count).Error; err != nil {
	return err
}
if count > 0 {
	zlog.Info("AI microservice config already initialized, skipping...")
	return nil
}
```
- 检查表中是否已有记录
- **幂等性保证**：重复调用不会插入重复数据
- 适用场景：容器重启、多实例部署时避免冲突

**第 27-48 行**：input_prediction 配置
```go
inputPredictConfig := map[string]interface{}{
	"debounce_ms":       500,    // 防抖延迟（毫秒）
	"max_input_chars":   500,    // 最大输入字符数
	"context_messages":  10,     // 使用最近10条聊天记录
	"enable_cache":      true,   // 启用缓存
	"cache_ttl":         300,    // 缓存5分钟
	"stream_enabled":    true,   // 启用流式输出
}
```
- **JSON 存储优势**：无需 ALTER TABLE 即可添加新配置项（如未来新增 `enable_spell_check`）
- **性能关键参数**：
  - `debounce_ms=500`：用户停止输入 500ms 后才发起预测，避免频繁请求
  - `context_messages=10`：平衡上下文准确性和 Token 成本

**第 50-62 行**：Prompt 模板设计
```go
inputPredictPrompt := `你是一个智能输入助手，根据用户当前输入和聊天上下文，预测用户可能想输入的后半句。

## 上下文（最近 {{context_count}} 条消息）：
{{context_messages}}

## 用户当前输入：
{{user_input}}

## 要求：
1. 预测应自然流畅，不超过 20 字
2. 避免重复用户已输入内容
3. 直接输出预测文本，不要解释
4. 若无法预测，输出空字符串`
```
- **占位符约定**：`{{user_input}}`, `{{context_messages}}` 在 Plugin 层替换
- **Prompt 工程最佳实践**：
  - 明确角色（"你是一个智能输入助手"）
  - 结构化输入（使用 Markdown 标题）
  - 明确约束（"不超过 20 字"、"直接输出"）
  - 边界处理（"若无法预测，输出空字符串"）

**第 72-96 行**：polish 配置（关键差异）
```go
polishPrompt := `你是文本润色专家，根据用户原文和上下文，提供 2-3 种不同风格的改写建议。

## 要求：
1. 保持原意，仅调整表达风格
2. 输出 JSON 格式：{"options": [{"style": "更礼貌", "text": "..."}, {"style": "更直接", "text": "..."}]}
3. style 字段限定：更礼貌/更直接/更专业/更活泼/更正式/更委婉
4. 最多返回 3 个选项`
```
- **JSON 输出格式**：要求 LLM 返回结构化数据，便于前端解析
- **风格限定**：防止 LLM 随意发挥（如返回"更搞笑"等不合适的风格）
- **数量控制**：`max_options=3` 避免选择过载（Hick's Law）

**第 98-125 行**：digest 配置（长上下文优化）
```go
digestModelConfig := map[string]interface{}{
	"provider":        "volcengine_ark",
	"model":           "doubao-pro-32k", // 使用长上下文模型
	"temperature":     0.5,              // 降低随机性
	"max_tokens":      500,
	"timeout_seconds": 15,               // 更长的超时时间
}
```
- **模型选择**：使用 `doubao-pro-32k`（支持 32K 上下文）而非 `doubao-lite-8k`
  - 原因：摘要需要处理最多 200 条消息，可能超过 8K 上下文窗口
  - 成本权衡：Pro 版本 ¥0.003/1K tokens（是 Lite 的 10 倍，但摘要频率低）
- **温度参数**：`temperature=0.5` 降低创造性，确保摘要准确
- **超时设置**：`timeout_seconds=15` 因为处理长文本耗时更久

**第 127-135 行**：批量插入
```go
configs := []*microservice.AIMicroserviceConfig{
	configInput,
	configPolish,
	configDigest,
}
result := db.Create(&configs)
```
- GORM 批量插入，减少数据库往返次数
- `&configs`：传递切片指针，避免大对象复制

---

#### 3.2.3 调用时机

在 `main.go` 或 `initial` 包的初始化流程中调用：

```go
// main.go 示例
package main

import (
	"OmniLink/internal/initial"
	aiPersistence "OmniLink/internal/modules/ai/infrastructure/persistence"
	// ... 其他导入
)

func main() {
	// 1. 初始化数据库连接（自动执行 AutoMigrate）
	// 此时已创建 ai_microservice_config 和 ai_microservice_call_log 表
	
	// 2. 初始化默认配置
	if err := aiPersistence.InitMicroserviceDefaultConfig(); err != nil {
		panic("Failed to init microservice config: " + err.Error())
	}

	// 3. 启动服务器
	// ...
}
```

**执行流程**：
1. **首次启动**：AutoMigrate 创建表 → InitMicroserviceDefaultConfig 插入 3 条默认配置
2. **后续启动**：AutoMigrate 检测表已存在跳过 → InitMicroserviceDefaultConfig 检测数据已存在跳过
3. **配置更新**：直接在数据库修改 `config_json` 或 `prompt_template` → 重启或热更新生效

---

## 4. SQL 参考脚本

> **说明**：GORM AutoMigrate 会自动生成 DDL，以下 SQL 仅供参考或手动执行（如需在 AutoMigrate 之前预创建表）。

### 4.1 创建表脚本

```sql
-- ============================================
-- 表 1: ai_microservice_config（服务配置表）
-- ============================================
CREATE TABLE IF NOT EXISTS `ai_microservice_config` (
  `id` BIGINT NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `service_type` VARCHAR(50) NOT NULL COMMENT '服务类型（input_prediction/polish/digest）',
  `is_enabled` TINYINT(1) NOT NULL DEFAULT 1 COMMENT '是否启用（0=禁用, 1=启用）',
  `config_json` JSON NOT NULL COMMENT '服务级配置（JSON 格式）',
  `model_config_json` JSON NOT NULL COMMENT '模型配置（JSON 格式）',
  `prompt_template` MEDIUMTEXT COMMENT 'Prompt 模板',
  `created_at` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `updated_at` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_service_type` (`service_type`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='AI 微服务配置表';

-- ============================================
-- 表 2: ai_microservice_call_log（调用日志表）
-- ============================================
CREATE TABLE IF NOT EXISTS `ai_microservice_call_log` (
  `id` BIGINT NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `request_id` CHAR(20) NOT NULL COMMENT '请求唯一 ID',
  `tenant_user_id` CHAR(20) NOT NULL COMMENT '租户用户 ID',
  `service_type` VARCHAR(50) NOT NULL COMMENT '服务类型',
  `input_text` MEDIUMTEXT COMMENT '用户输入文本',
  `output_text` MEDIUMTEXT COMMENT 'AI 生成结果',
  `context_json` JSON COMMENT '上下文信息',
  `latency_ms` INT COMMENT '请求延迟（毫秒）',
  `tokens_used` INT COMMENT '消耗 Token 数',
  `is_cached` TINYINT(1) DEFAULT 0 COMMENT '是否命中缓存（0=未命中, 1=命中）',
  `error_msg` TEXT COMMENT '错误信息',
  `created_at` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_request_id` (`request_id`),
  KEY `idx_tenant_user_id` (`tenant_user_id`),
  KEY `idx_service_type` (`service_type`),
  KEY `idx_created_at` (`created_at`),
  KEY `idx_tenant_service_time` (`tenant_user_id`, `service_type`, `created_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='AI 微服务调用日志表';
```

### 4.2 索引说明

| 表名 | 索引名 | 类型 | 列 | 用途 |
|------|--------|------|-----|------|
| `ai_microservice_config` | `idx_service_type` | UNIQUE | `service_type` | 按服务类型查询配置（高频，单条） |
| `ai_microservice_call_log` | `idx_request_id` | UNIQUE | `request_id` | 幂等性检查（去重） |
| `ai_microservice_call_log` | `idx_tenant_user_id` | INDEX | `tenant_user_id` | 按用户查询历史记录 |
| `ai_microservice_call_log` | `idx_service_type` | INDEX | `service_type` | 按服务类型统计（如 polish 调用次数） |
| `ai_microservice_call_log` | `idx_created_at` | INDEX | `created_at` | 按时间范围查询（如最近 7 天日志） |
| `ai_microservice_call_log` | `idx_tenant_service_time` | INDEX | `tenant_user_id`, `service_type`, `created_at` | 联合查询（如某用户某服务最近调用记录） |

**索引设计原则**：
- **高频查询优先**：`service_type` 查询频繁（每次请求读取配置）→ UNIQUE 索引
- **聚合统计优化**：`idx_tenant_service_time` 联合索引覆盖常见分组查询
- **避免过度索引**：未对 `latency_ms`、`tokens_used` 建索引（低频查询，可全表扫描）

---

## 5. 执行步骤

### 5.1 自动执行（推荐）

**适用场景**：开发环境、首次部署、容器化部署

```bash
# 1. 确保数据库连接配置正确
vim config/config_local.toml
# 检查 [mysql] 配置段

# 2. 启动应用（GORM 自动执行迁移）
go run main.go

# 3. 检查日志输出
# 应包含以下日志：
# [INFO] Database migration completed successfully
# [INFO] Default AI microservice configurations initialized successfully
```

**自动执行原理**：
```
启动流程：
main.go init()
  ↓
initial.gorm.go init()
  ↓
GormDB.AutoMigrate(&aiMicroservice.AIMicroserviceConfig{}, ...)
  ↓
（表不存在）→ 自动创建表
（表已存在）→ 跳过
  ↓
main()
  ↓
aiPersistence.InitMicroserviceDefaultConfig()
  ↓
（配置表为空）→ 插入 3 条默认配置
（配置已存在）→ 跳过
```

---

### 5.2 手动执行（可选）

**适用场景**：生产环境、需要 DBA 审核 SQL、不使用 GORM AutoMigrate

#### 步骤 1：手动创建表

```bash
# 连接数据库
mysql -h <host> -u <user> -p <database>

# 执行建表脚本（见 4.1 节）
source scripts/migrations/000010_ai_microservice.up.sql
```

#### 步骤 2：验证表结构

```sql
-- 检查表是否创建成功
SHOW TABLES LIKE 'ai_microservice%';

-- 检查索引
SHOW INDEX FROM ai_microservice_config;
SHOW INDEX FROM ai_microservice_call_log;

-- 检查字段
DESC ai_microservice_config;
DESC ai_microservice_call_log;
```

#### 步骤 3：插入初始数据

```bash
# 启动应用（仅执行 InitMicroserviceDefaultConfig）
go run main.go
```

或手动执行 SQL：

```sql
-- 示例：手动插入 input_prediction 配置
INSERT INTO ai_microservice_config (
  service_type, 
  is_enabled, 
  config_json, 
  model_config_json, 
  prompt_template, 
  created_at, 
  updated_at
) VALUES (
  'input_prediction',
  1,
  '{"debounce_ms":500,"max_input_chars":500,"context_messages":10,"enable_cache":true,"cache_ttl":300,"stream_enabled":true}',
  '{"provider":"volcengine_ark","model":"doubao-lite-8k","api_key":"env:DOUBAO_API_KEY","base_url":"https://ark.cn-beijing.volces.com/api/v3","temperature":0.7,"max_tokens":50,"timeout_seconds":5}',
  '你是一个智能输入助手...',  -- （完整 Prompt 见 3.2.1 节）
  NOW(),
  NOW()
);

-- 重复以上语句插入 polish 和 digest 配置
```

---

## 6. 验证与测试

### 6.1 数据验证

```sql
-- 1. 检查配置表数据
SELECT 
  service_type, 
  is_enabled, 
  JSON_EXTRACT(model_config_json, '$.model') AS model,
  JSON_EXTRACT(config_json, '$.cache_ttl') AS cache_ttl
FROM ai_microservice_config;

-- 预期输出：
-- +------------------+------------+-------------------+-----------+
-- | service_type     | is_enabled | model             | cache_ttl |
-- +------------------+------------+-------------------+-----------+
-- | input_prediction |          1 | "doubao-lite-8k"  | 300       |
-- | polish           |          1 | "doubao-lite-8k"  | 1800      |
-- | digest           |          1 | "doubao-pro-32k"  | 600       |
-- +------------------+------------+-------------------+-----------+

-- 2. 检查日志表（初始应为空）
SELECT COUNT(*) FROM ai_microservice_call_log;
-- 预期输出：0
```

### 6.2 功能测试

#### 测试 1：读取配置

```go
// 在任意服务层代码中测试
package service

import (
	"OmniLink/internal/initial"
	"OmniLink/internal/modules/ai/domain/microservice"
	"testing"
)

func TestLoadConfig(t *testing.T) {
	var config microservice.AIMicroserviceConfig
	result := initial.GormDB.
		Where("service_type = ?", "input_prediction").
		First(&config)
	
	if result.Error != nil {
		t.Fatal("Failed to load config:", result.Error)
	}
	
	if config.IsEnabled != 1 {
		t.Error("Expected is_enabled = 1")
	}
	
	// 解析 JSON 配置
	var modelConfig map[string]interface{}
	json.Unmarshal([]byte(config.ModelConfigJson), &modelConfig)
	
	if modelConfig["model"] != "doubao-lite-8k" {
		t.Error("Expected model = doubao-lite-8k")
	}
}
```

#### 测试 2：写入日志

```go
func TestWriteLog(t *testing.T) {
	log := &microservice.AIMicroserviceCallLog{
		RequestId:     "test_req_12345",
		TenantUserId:  "user_001",
		ServiceType:   "input_prediction",
		InputText:     "你好",
		OutputText:    "，有什么可以帮助你的？",
		LatencyMs:     120,
		TokensUsed:    15,
		IsCached:      0,
	}
	
	result := initial.GormDB.Create(log)
	if result.Error != nil {
		t.Fatal("Failed to write log:", result.Error)
	}
	
	// 验证唯一索引
	duplicateLog := *log
	duplicateLog.Id = 0
	result = initial.GormDB.Create(&duplicateLog)
	
	// 预期失败（request_id 重复）
	if result.Error == nil {
		t.Error("Expected unique constraint violation")
	}
}
```

### 6.3 性能测试

```sql
-- 测试索引效果（需先插入测试数据）

-- 查询 1：按 service_type 查询（应使用 idx_service_type）
EXPLAIN SELECT * FROM ai_microservice_config WHERE service_type = 'polish';
-- 预期：type=const, key=idx_service_type

-- 查询 2：按用户和时间查询日志（应使用 idx_tenant_service_time）
EXPLAIN SELECT * FROM ai_microservice_call_log 
WHERE tenant_user_id = 'user_001' 
  AND service_type = 'input_prediction'
  AND created_at >= '2026-02-01'
ORDER BY created_at DESC
LIMIT 20;
-- 预期：type=range, key=idx_tenant_service_time

-- 查询 3：统计调用次数（应使用 idx_service_type）
EXPLAIN SELECT service_type, COUNT(*) 
FROM ai_microservice_call_log 
GROUP BY service_type;
-- 预期：type=index, key=idx_service_type
```

---

## 7. 回滚方案

### 7.1 删除表（慎用）

```sql
-- 生产环境禁止直接删除！应先备份数据
-- mysqldump -u <user> -p <database> ai_microservice_config ai_microservice_call_log > backup.sql

DROP TABLE IF EXISTS ai_microservice_call_log;
DROP TABLE IF EXISTS ai_microservice_config;
```

### 7.2 禁用功能（保留表）

```sql
-- 方案 1：禁用所有微服务
UPDATE ai_microservice_config SET is_enabled = 0;

-- 方案 2：禁用单个服务
UPDATE ai_microservice_config SET is_enabled = 0 WHERE service_type = 'polish';
```

### 7.3 代码回滚

**移除 GORM AutoMigrate 注册**：

```go
// internal/initial/gorm.go
err = GormDB.AutoMigrate(
	// ... 其他表
	
	// 注释掉以下两行
	// &aiMicroservice.AIMicroserviceConfig{},
	// &aiMicroservice.AIMicroserviceCallLog{},
)
```

**移除初始化调用**：

```go
// main.go
// 注释掉以下行
// aiPersistence.InitMicroserviceDefaultConfig()
```

---

## 8. 索引优化说明

### 8.1 联合索引选择策略

**`idx_tenant_service_time` 联合索引分析**：

```sql
KEY `idx_tenant_service_time` (`tenant_user_id`, `service_type`, `created_at`)
```

**为什么是这个顺序？**

根据 **最左前缀原则** 和 **查询模式**：

| 查询场景 | SQL 示例 | 使用的索引列 | 是否覆盖？ |
|----------|----------|-------------|-----------|
| 按用户查所有日志 | `WHERE tenant_user_id = 'u1'` | `tenant_user_id` | ✅ |
| 按用户+服务查询 | `WHERE tenant_user_id = 'u1' AND service_type = 'polish'` | `tenant_user_id`, `service_type` | ✅ |
| 按用户+服务+时间 | `WHERE tenant_user_id = 'u1' AND service_type = 'polish' AND created_at >= '2026-02-01'` | 所有列 | ✅ |
| 仅按服务查询 | `WHERE service_type = 'polish'` | ❌（需走 `idx_service_type`） | ✅（单列索引） |
| 仅按时间查询 | `WHERE created_at >= '2026-02-01'` | ❌（需走 `idx_created_at`） | ✅（单列索引） |

**设计决策**：
- `tenant_user_id` 放第一位：用户维度查询最频繁（"我的历史记录"）
- `service_type` 放第二位：常与用户维度组合（"我的 polish 记录"）
- `created_at` 放第三位：时间范围过滤通常是附加条件

### 8.2 单列索引补充

为覆盖非最左前缀查询，额外建立单列索引：

```sql
KEY `idx_service_type` (`service_type`)    -- 按服务统计（如 GROUP BY service_type）
KEY `idx_created_at` (`created_at`)        -- 按时间范围清理历史数据
```

### 8.3 索引维护

**定期检查索引使用率**：

```sql
-- 查看索引统计（MySQL 5.7+）
SELECT 
  TABLE_NAME,
  INDEX_NAME,
  CARDINALITY,
  SEQ_IN_INDEX
FROM information_schema.STATISTICS
WHERE TABLE_SCHEMA = 'omnilink' 
  AND TABLE_NAME = 'ai_microservice_call_log';

-- 查看索引实际使用情况（需开启 performance_schema）
SELECT 
  OBJECT_NAME,
  INDEX_NAME,
  COUNT_STAR,
  COUNT_READ,
  SUM_TIMER_WAIT
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE OBJECT_SCHEMA = 'omnilink' 
  AND OBJECT_NAME = 'ai_microservice_call_log';
```

**清理未使用索引**（生产环境谨慎）：
```sql
-- 若发现某索引从未被使用（COUNT_READ = 0），可考虑删除
-- ALTER TABLE ai_microservice_call_log DROP INDEX idx_unused_index;
```

---

## 9. 总结与下一步

### 9.1 本部分完成内容

| 任务 | 状态 | 产出物 |
|------|------|--------|
| 表结构设计 | ✅ | 2 张表 + 6 个索引 |
| GORM 实体集成 | ✅ | `gorm.go` 修改方案 |
| 初始数据脚本 | ✅ | `init_microservice_config.go`（完整代码） |
| SQL 参考脚本 | ✅ | 建表 SQL + 索引 SQL |
| 验证测试方案 | ✅ | 单元测试 + SQL 验证查询 |

### 9.2 待完成任务

1. **Part 7: 前端实现**（~900 行）
   - WebSocket 连接管理
   - 半透明预测文本渲染
   - 润色按钮交互
   - 摘要卡片组件

2. **Part 8: 测试与验证**
   - 单元测试（Plugin、Pipeline、Service 层）
   - 集成测试（完整请求链路）
   - 性能测试（QPS、P99 延迟）

3. **Part 9: 部署与监控**
   - Docker 配置
   - 环境变量清单
   - Prometheus 指标埋点
   - 告警规则配置

### 9.3 立即可执行步骤

```bash
# 1. 修改 gorm.go（添加 AutoMigrate）
vim internal/initial/gorm.go
# 按 3.1.1 节修改

# 2. 创建初始化脚本
mkdir -p internal/modules/ai/infrastructure/persistence
vim internal/modules/ai/infrastructure/persistence/init_microservice_config.go
# 粘贴 3.2.1 节代码

# 3. 在 main.go 中调用初始化
vim main.go
# 添加：aiPersistence.InitMicroserviceDefaultConfig()

# 4. 启动应用验证
go run main.go

# 5. 检查数据库
mysql -u root -p -e "USE omnilink; SELECT * FROM ai_microservice_config;"
```

---

## 10. FAQ

**Q1: 为什么使用 JSON 字段而非单独的列？**

A: 权衡灵活性与查询性能：
- ✅ **优势**：无需频繁 ALTER TABLE，配置项可动态扩展
- ✅ **优势**：支持复杂嵌套结构（如 `model_config_json` 包含多个参数）
- ❌ **劣势**：无法在 JSON 内部字段建索引（MySQL 5.7+ 支持生成列索引，但本项目未使用）
- ✅ **适用场景**：配置表（低频查询，高频更新）

**Q2: 日志表数据量过大如何处理？**

A: 三阶段策略：
1. **热数据**（最近 7 天）：保留在 MySQL，支持实时查询
2. **温数据**（8-90 天）：每日归档到对象存储（OSS/S3），MySQL 保留摘要索引
3. **冷数据**（90 天+）：仅保留在对象存储，按需下载分析

实现方案：
```sql
-- 定时任务（每日凌晨执行）
-- 1. 导出 8 天前的数据
SELECT * FROM ai_microservice_call_log 
WHERE created_at < DATE_SUB(NOW(), INTERVAL 8 DAY)
INTO OUTFILE '/data/archive/call_log_20260201.csv';

-- 2. 上传到对象存储
-- aws s3 cp /data/archive/call_log_20260201.csv s3://omnilink/logs/

-- 3. 删除已归档数据
DELETE FROM ai_microservice_call_log 
WHERE created_at < DATE_SUB(NOW(), INTERVAL 8 DAY);
```

**Q3: 如何更新 Prompt 模板？**

A: 三种方式：
```sql
-- 方式 1：直接修改数据库（立即生效，需重启或热更新）
UPDATE ai_microservice_config 
SET prompt_template = '新的 Prompt 内容...',
    updated_at = NOW()
WHERE service_type = 'input_prediction';

-- 方式 2：通过管理后台界面（需实现配置管理页面）
-- POST /admin/ai/microservice/config
-- { "service_type": "polish", "prompt_template": "..." }

-- 方式 3：版本控制 + CI/CD（推荐生产环境）
-- 1. 在代码中维护 Prompt 版本（如 prompts/v2/input_prediction.txt）
-- 2. 通过 InitMicroserviceDefaultConfig 的变种函数更新
```

**Q4: GORM AutoMigrate 是否安全？**

A: 分场景：
- ✅ **开发环境**：完全安全，自动同步表结构
- ⚠️ **生产环境**：谨慎使用，建议：
  1. 首次部署前先在测试环境验证
  2. 关闭 AutoMigrate，改用人工审核的迁移脚本
  3. 若使用 AutoMigrate，设置 `GORM_AUTO_MIGRATE=false` 环境变量控制

生产环境推荐流程：
```go
// config/config.go
type Config struct {
	EnableAutoMigrate bool `mapstructure:"enable_auto_migrate"`
	// ...
}

// internal/initial/gorm.go
if config.GetConfig().EnableAutoMigrate {
	GormDB.AutoMigrate(...)
} else {
	zlog.Info("AutoMigrate disabled, please run migrations manually")
}
```

---

**文档结束** | 下一步：[Part 7 - 前端实现](./模块三_超详细实施指南_第7部分_前端实现.md)
