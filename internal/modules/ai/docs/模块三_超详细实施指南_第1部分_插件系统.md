# 模块三 AI 微服务/小工具 - 超详细实施指南

## 文档说明

本文档包含模块三所有代码的完整实现，每个文件都有：
- ✅ 完整的代码内容
- ✅ 逐行/逐段详细注释
- ✅ 设计原理说明
- ✅ 测试方法
- ✅ 常见问题排查

---

## 目录

- [第一部分：Infrastructure Layer - 插件系统](#第一部分infrastructure-layer---插件系统)
  - [1.1 插件接口定义](#11-插件接口定义)
  - [1.2 智能输入插件](#12-智能输入插件)
  - [1.3 润色插件](#13-润色插件)
  - [1.4 摘要插件](#14-摘要插件)
- [第二部分：Infrastructure Layer - Pipeline](#第二部分infrastructure-layer---pipeline)
  - [2.1 微服务 Pipeline](#21-微服务-pipeline)
  - [2.2 轻量模型 Provider](#22-轻量模型-provider)
- [第三部分：Application Layer - Service](#第三部分application-layer---service)
  - [3.1 微服务 Service](#31-微服务-service)
- [第四部分：Interface Layer - Handlers](#第四部分interface-layer---handlers)
  - [4.1 HTTP Handler](#41-http-handler)
  - [4.2 WebSocket Handler](#42-websocket-handler)
- [第五部分：配置和路由](#第五部分配置和路由)
  - [5.1 配置文件修改](#51-配置文件修改)
  - [5.2 路由注册](#52-路由注册)
- [第六部分：数据库迁移](#第六部分数据库迁移)
- [第七部分：前端实现](#第七部分前端实现)
  - [7.1 API 服务](#71-api-服务)
  - [7.2 WebSocket 管理器](#72-websocket-管理器)
  - [7.3 输入框组件](#73-输入框组件)
  - [7.4 润色组件](#74-润色组件)
  - [7.5 摘要组件](#75-摘要组件)
- [第八部分：测试指南](#第八部分测试指南)
- [第九部分：部署清单](#第九部分部署清单)

---

# 第一部分：Infrastructure Layer - 插件系统

## 1.1 插件接口定义

### 文件路径
```
internal/modules/ai/infrastructure/plugins/plugin_interface.go
```

### 完整代码

```go
package plugins

import (
	"context"
	"github.com/cloudwego/eino/schema"
)

// MicroservicePlugin 微服务插件接口
//
// 设计原理：
// 1. 插件化架构：每个 AI 微服务功能都是一个独立插件
// 2. 统一接口：所有插件实现相同接口，方便扩展和管理
// 3. 职责分离：每个插件只负责自己的业务逻辑
//
// 使用场景：
// - 新增功能时，只需实现此接口即可
// - Pipeline 通过此接口调用插件，无需关心具体实现
type MicroservicePlugin interface {
	// GetServiceType 获取服务类型
	// 
	// 返回值：input_prediction / polish / digest 等
	// 用途：Pipeline 根据此值路由到对应插件
	GetServiceType() string

	// BuildPrompt 构建 LLM Prompt
	//
	// 参数：
	//   - ctx: 上下文
	//   - req: 插件请求（包含用户输入和上下文）
	//
	// 返回值：
	//   - []schema.Message: Eino 标准消息格式（System/User/Assistant）
	//   - error: 构建失败时返回错误
	//
	// 设计要点：
	// - 每个插件根据自己的需求构建不同的 Prompt
	// - 返回 Eino 标准格式，方便 Pipeline 统一处理
	BuildPrompt(ctx context.Context, req *PluginRequest) ([]schema.Message, error)

	// ParseResponse 解析 LLM 响应
	//
	// 参数：
	//   - ctx: 上下文
	//   - llmOutput: LLM 原始输出（纯文本或 JSON）
	//   - req: 原始请求（用于上下文信息）
	//
	// 返回值：
	//   - *PluginResponse: 标准化的插件响应
	//   - error: 解析失败时返回错误
	//
	// 设计要点：
	// - 将 LLM 的原始输出转换为结构化数据
	// - 处理 JSON 解析失败等异常情况
	ParseResponse(ctx context.Context, llmOutput string, req *PluginRequest) (*PluginResponse, error)

	// Validate 验证请求参数
	//
	// 参数：
	//   - ctx: 上下文
	//   - req: 插件请求
	//
	// 返回值：
	//   - error: 验证失败时返回错误，成功返回 nil
	//
	// 设计要点：
	// - 在调用 LLM 之前验证参数，避免浪费 API 调用
	// - 每个插件可以定义自己的验证规则
	Validate(ctx context.Context, req *PluginRequest) error

	// GetCacheKey 获取缓存 Key
	//
	// 参数：
	//   - ctx: 上下文
	//   - req: 插件请求
	//
	// 返回值：
	//   - string: 缓存 Key（空字符串表示不缓存）
	//
	// 设计要点：
	// - 相同输入生成相同 Key，实现缓存复用
	// - 通常使用 MD5(input + context) 作为 Key
	// - 返回空字符串可以禁用缓存
	GetCacheKey(ctx context.Context, req *PluginRequest) string

	// GetCacheTTL 获取缓存 TTL（秒）
	//
	// 返回值：
	//   - int: 缓存存活时间（秒）
	//
	// 设计要点：
	// - 不同功能的缓存时间不同
	// - 智能输入：300s（5分钟）
	// - 润色：1800s（30分钟）
	// - 摘要：600s（10分钟）
	GetCacheTTL() int
}

// PluginRequest 插件请求
//
// 设计原理：
// - 统一的请求结构，所有插件共享
// - 使用 map 存储上下文，保证灵活性
type PluginRequest struct {
	TenantUserID string                 `json:"tenant_user_id"` // 用户 ID（租户隔离）
	ServiceType  string                 `json:"service_type"`   // 服务类型
	Input        string                 `json:"input"`          // 输入文本
	Context      map[string]interface{} `json:"context"`        // 上下文信息（如历史消息）
	CustomConfig map[string]interface{} `json:"custom_config"`  // 自定义配置（可选）
}

// PluginResponse 插件响应
//
// 设计原理：
// - 统一的响应结构
// - 包含性能指标（缓存命中、Token 消耗）
type PluginResponse struct {
	Output     string                 `json:"output"`      // 输出文本或 JSON
	Metadata   map[string]interface{} `json:"metadata"`    // 元数据（如选项数量）
	CacheHit   bool                   `json:"cache_hit"`   // 是否命中缓存
	TokensUsed int                    `json:"tokens_used"` // 消耗 Token 数
}
```

### 代码说明

#### 为什么这样设计？

1. **插件接口模式**
   - ✅ 新增功能无需修改 Pipeline，只需实现接口
   - ✅ 每个插件职责单一，易于测试
   - ✅ 可以动态注册/卸载插件

2. **标准化请求/响应**
   - ✅ 使用 `map[string]interface{}` 保证灵活性
   - ✅ 所有插件共享相同的数据结构
   - ✅ 便于序列化和日志记录

3. **缓存策略内置**
   - ✅ 每个插件自己决定是否缓存
   - ✅ GetCacheKey 返回空字符串可禁用缓存
   - ✅ 支持不同的 TTL 策略

#### 如何使用？

```go
// 示例：注册插件
pipeline := NewMicroservicePipeline(chatModel, cache)
pipeline.RegisterPlugin(NewInputPredictionPlugin(nil))
pipeline.RegisterPlugin(NewPolishPlugin(nil))

// 示例：调用插件
req := &PluginRequest{
    ServiceType: "input_prediction",
    Input:       "今天天气真不错",
    Context:     map[string]interface{}{"messages": []},
}
resp, err := pipeline.Execute(ctx, req)
```

---

## 1.2 智能输入插件

### 文件路径
```
internal/modules/ai/infrastructure/plugins/input_prediction_plugin.go
```

### 完整代码

```go
package plugins

import (
	"context"
	"crypto/md5"
	"encoding/hex"
	"fmt"
	"strings"

	"github.com/cloudwego/eino/schema"
)

// InputPredictionPlugin 智能输入预测插件
//
// 功能：根据用户当前输入和聊天历史，预测后半句
//
// 使用场景：
// - 用户在输入框输入文字时，实时提供补全建议
// - 类似 Gmail 的智能回复功能
type InputPredictionPlugin struct {
	config *InputPredictionConfig
}

// InputPredictionConfig 智能输入配置
type InputPredictionConfig struct {
	ContextMessages int // 上下文消息数（默认 10）
	MaxInputChars   int // 最大输入字符（默认 500）
	CacheTTL        int // 缓存 TTL（秒，默认 300）
}

// NewInputPredictionPlugin 创建智能输入插件
//
// 参数：
//   - config: 配置（传 nil 使用默认配置）
//
// 返回值：
//   - *InputPredictionPlugin: 插件实例
func NewInputPredictionPlugin(config *InputPredictionConfig) *InputPredictionPlugin {
	// 使用默认配置
	if config == nil {
		config = &InputPredictionConfig{
			ContextMessages: 10,
			MaxInputChars:   500,
			CacheTTL:        300,
		}
	}
	return &InputPredictionPlugin{config: config}
}

// GetServiceType 实现 MicroservicePlugin 接口
func (p *InputPredictionPlugin) GetServiceType() string {
	return "input_prediction"
}

// BuildPrompt 构建智能输入的 Prompt
//
// Prompt 设计原理：
// 1. System Message：定义 AI 的角色和规则
// 2. Context：提供聊天历史，帮助 AI 理解语境
// 3. User Message：明确要求 AI 预测后半句
//
// 注意事项：
// - 只返回补全部分，不重复用户已输入内容
// - 预测内容要简短（< 20 字）
// - 如果无法预测，返回空字符串
func (p *InputPredictionPlugin) BuildPrompt(ctx context.Context, req *PluginRequest) ([]schema.Message, error) {
	// 1. 提取上下文消息
	var contextMsgs []map[string]string
	if msgs, ok := req.Context["messages"].([]interface{}); ok {
		for _, msg := range msgs {
			if m, ok := msg.(map[string]interface{}); ok {
				contextMsgs = append(contextMsgs, map[string]string{
					"role":    fmt.Sprintf("%v", m["role"]),
					"content": fmt.Sprintf("%v", m["content"]),
				})
			}
		}
	}

	// 2. 限制上下文数量（避免 Prompt 过长）
	if len(contextMsgs) > p.config.ContextMessages {
		contextMsgs = contextMsgs[len(contextMsgs)-p.config.ContextMessages:]
	}

	// 3. 构建 System Prompt
	// 
	// 设计要点：
	// - 明确 AI 的角色（智能输入助手）
	// - 定义输出规则（简短、不重复、符合语境）
	// - 提供失败处理（无法预测时返回空）
	systemPrompt := `你是一个智能输入助手。根据用户当前输入和聊天历史，预测用户想说的后半句。

规则：
1. 预测内容要简短（< 20 字）
2. 符合聊天语境和用户语气
3. 只返回补全部分，不要重复用户已输入的内容
4. 如果无法预测，返回空字符串`

	// 4. 构建上下文字符串
	contextStr := ""
	for _, msg := range contextMsgs {
		contextStr += fmt.Sprintf("[%s]: %s\n", msg["role"], msg["content"])
	}

	// 5. 构建 User Message
	userPrompt := fmt.Sprintf(`聊天历史：
%s

用户当前输入：%s

请预测后半句（只返回补全部分）：`, contextStr, req.Input)

	// 6. 返回 Eino 标准消息格式
	return []schema.Message{
		{Role: schema.System, Content: systemPrompt},
		{Role: schema.User, Content: userPrompt},
	}, nil
}

// ParseResponse 解析 LLM 响应
//
// 智能输入的响应很简单，直接返回 LLM 输出即可
func (p *InputPredictionPlugin) ParseResponse(ctx context.Context, llmOutput string, req *PluginRequest) (*PluginResponse, error) {
	// 去除前后空格
	prediction := strings.TrimSpace(llmOutput)

	return &PluginResponse{
		Output:     prediction,
		CacheHit:   false, // 由 Pipeline 层填充
		TokensUsed: 0,     // 由 Pipeline 层填充
	}, nil
}

// Validate 验证请求参数
func (p *InputPredictionPlugin) Validate(ctx context.Context, req *PluginRequest) error {
	// 1. 检查输入是否为空
	if req.Input == "" {
		return fmt.Errorf("input is required")
	}

	// 2. 检查输入长度
	if len(req.Input) > p.config.MaxInputChars {
		return fmt.Errorf("input too long (max %d chars)", p.config.MaxInputChars)
	}

	return nil
}

// GetCacheKey 生成缓存 Key
//
// 设计原理：
// - 对 "输入 + 上下文" 生成 MD5 Hash
// - 相同输入和上下文生成相同 Key，实现缓存复用
//
// Key 格式：ai:micro:input:{user_id}:{hash}
func (p *InputPredictionPlugin) GetCacheKey(ctx context.Context, req *PluginRequest) string {
	// 1. 拼接输入和上下文
	data := fmt.Sprintf("%s|%v", req.Input, req.Context["messages"])

	// 2. 计算 MD5 Hash
	hash := md5.Sum([]byte(data))
	hashStr := hex.EncodeToString(hash[:])

	// 3. 返回缓存 Key
	return fmt.Sprintf("ai:micro:input:%s:%s", req.TenantUserID, hashStr)
}

// GetCacheTTL 返回缓存 TTL
func (p *InputPredictionPlugin) GetCacheTTL() int {
	return p.config.CacheTTL
}
```

### 代码说明

#### 核心设计要点

1. **Prompt 工程**
   ```
   System Prompt: 定义角色和规则
   ↓
   Context: 聊天历史（最近10条）
   ↓
   User Prompt: 明确任务（预测后半句）
   ```

2. **上下文管理**
   - ✅ 限制上下文数量（避免超过 LLM 窗口）
   - ✅ 只取最近的消息（更相关）
   - ✅ 支持灵活的上下文格式

3. **缓存策略**
   - ✅ MD5(input + context) 作为 Key
   - ✅ 相同输入复用缓存，减少 API 调用
   - ✅ TTL 5分钟（平衡性能和成本）

#### 测试方法

```go
// 单元测试示例
func TestInputPredictionPlugin_BuildPrompt(t *testing.T) {
    plugin := NewInputPredictionPlugin(nil)
    
    req := &PluginRequest{
        Input: "今天天气真不错，要不要一起",
        Context: map[string]interface{}{
            "messages": []interface{}{
                map[string]interface{}{"role": "user", "content": "在吗？"},
                map[string]interface{}{"role": "assistant", "content": "在的"},
            },
        },
    }
    
    msgs, err := plugin.BuildPrompt(context.Background(), req)
    assert.NoError(t, err)
    assert.Len(t, msgs, 2) // System + User
    assert.Contains(t, msgs[1].Content, "今天天气真不错")
}
```

---

## 1.3 润色插件

### 文件路径
```
internal/modules/ai/infrastructure/plugins/polish_plugin.go
```

### 完整代码

```go
package plugins

import (
	"context"
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"strings"

	"github.com/cloudwego/eino/schema"
)

// PolishPlugin 文本润色插件
//
// 功能：根据用户输入的句子，提供 2-3 个润色建议
//
// 使用场景：
// - 用户输入完整句子后，提供"更礼貌"、"更简洁"等选项
// - 一键替换输入框内容
type PolishPlugin struct {
	config *PolishConfig
}

// PolishConfig 润色配置
type PolishConfig struct {
	MaxOptions int // 最多返回选项数（默认 3）
	CacheTTL   int // 缓存 TTL（秒，默认 1800）
}

// NewPolishPlugin 创建润色插件
func NewPolishPlugin(config *PolishConfig) *PolishPlugin {
	if config == nil {
		config = &PolishConfig{
			MaxOptions: 3,
			CacheTTL:   1800,
		}
	}
	return &PolishPlugin{config: config}
}

func (p *PolishPlugin) GetServiceType() string {
	return "polish"
}

// BuildPrompt 构建润色 Prompt
//
// Prompt 设计原理：
// 1. 要求 LLM 返回结构化 JSON（而非纯文本）
// 2. 限制选项类型（更礼貌/更简洁/更强硬/更委婉）
// 3. 保证意思不变，只改变语气和风格
func (p *PolishPlugin) BuildPrompt(ctx context.Context, req *PluginRequest) ([]schema.Message, error) {
	systemPrompt := `你是一个智能文本润色助手。分析用户输入的句子，给出 2-3 个润色建议。

输出格式（JSON）：
{
  "polishes": [
    {"label": "更礼貌", "text": "润色后的文本"},
    {"label": "更简洁", "text": "润色后的文本"}
  ]
}

规则：
1. label 必须是："更礼貌"、"更简洁"、"更强硬"、"更委婉"之一
2. 每个选项必须与原句意思一致，只改变语气或风格
3. 如果原句已经很好，可以只返回 1-2 个选项
4. 返回的必须是有效的 JSON 格式`

	userPrompt := fmt.Sprintf("请为以下句子提供润色建议：\n\n%s", req.Input)

	return []schema.Message{
		{Role: schema.System, Content: systemPrompt},
		{Role: schema.User, Content: userPrompt},
	}, nil
}

// ParseResponse 解析润色响应
//
// 设计要点：
// - LLM 应返回 JSON 格式
// - 如果 JSON 解析失败，进行降级处理（返回原始文本）
func (p *PolishPlugin) ParseResponse(ctx context.Context, llmOutput string, req *PluginRequest) (*PluginResponse, error) {
	// 尝试解析 JSON
	var result struct {
		Polishes []struct {
			Label string `json:"label"`
			Text  string `json:"text"`
		} `json:"polishes"`
	}

	// 清理可能的 Markdown 代码块标记
	cleanedOutput := strings.TrimSpace(llmOutput)
	cleanedOutput = strings.TrimPrefix(cleanedOutput, "```json")
	cleanedOutput = strings.TrimPrefix(cleanedOutput, "```")
	cleanedOutput = strings.TrimSuffix(cleanedOutput, "```")
	cleanedOutput = strings.TrimSpace(cleanedOutput)

	if err := json.Unmarshal([]byte(cleanedOutput), &result); err != nil {
		// JSON 解析失败，降级处理
		return &PluginResponse{
			Output: llmOutput, // 直接返回原始输出
			Metadata: map[string]interface{}{
				"parse_error": err.Error(),
				"raw_output":  llmOutput,
			},
		}, nil
	}

	// 限制选项数量
	if len(result.Polishes) > p.config.MaxOptions {
		result.Polishes = result.Polishes[:p.config.MaxOptions]
	}

	// 重新序列化为 JSON
	outputJSON, _ := json.Marshal(result)

	return &PluginResponse{
		Output: string(outputJSON),
		Metadata: map[string]interface{}{
			"options_count": len(result.Polishes),
		},
	}, nil
}

func (p *PolishPlugin) Validate(ctx context.Context, req *PluginRequest) error {
	if req.Input == "" {
		return fmt.Errorf("input is required")
	}
	return nil
}

// GetCacheKey 生成缓存 Key
//
// 润色功能只依赖输入文本，不依赖上下文
// 所以缓存 Key 只需要对输入文本做 Hash
func (p *PolishPlugin) GetCacheKey(ctx context.Context, req *PluginRequest) string {
	hash := md5.Sum([]byte(req.Input))
	return fmt.Sprintf("ai:micro:polish:%s", hex.EncodeToString(hash[:]))
}

func (p *PolishPlugin) GetCacheTTL() int {
	return p.config.CacheTTL
}
```

### 代码说明

#### 核心设计要点

1. **结构化输出**
   - ✅ 要求 LLM 返回 JSON（而非纯文本）
   - ✅ 定义明确的 JSON Schema
   - ✅ 降级处理：JSON 解析失败时返回原始文本

2. **选项限制**
   - ✅ 最多 3 个选项（避免选择困难）
   - ✅ label 限定为固定类型
   - ✅ 保证意思不变

3. **缓存策略**
   - ✅ 只对输入文本做 Hash（不依赖上下文）
   - ✅ TTL 30分钟（润色结果相对稳定）

#### 测试方法

```go
func TestPolishPlugin_ParseResponse(t *testing.T) {
    plugin := NewPolishPlugin(nil)
    
    llmOutput := `{
        "polishes": [
            {"label": "更礼貌", "text": "麻烦您发一下那个文件"},
            {"label": "更简洁", "text": "请发文件"}
        ]
    }`
    
    resp, err := plugin.ParseResponse(context.Background(), llmOutput, nil)
    assert.NoError(t, err)
    assert.Contains(t, resp.Output, "更礼貌")
}
```

---

## 1.4 摘要插件

### 文件路径
```
internal/modules/ai/infrastructure/plugins/digest_plugin.go
```

### 完整代码

```go
package plugins

import (
	"context"
	"crypto/md5"
	"encoding/hex"
	"fmt"
	"strings"

	"github.com/cloudwego/eino/schema"
)

// DigestPlugin 消息摘要插件
//
// 功能：分析群聊消息，生成摘要
//
// 使用场景：
// - 群聊未读消息 > 50 条时，提供摘要
// - 帮助用户快速了解错过的讨论
type DigestPlugin struct {
	config *DigestConfig
}

// DigestConfig 摘要配置
type DigestConfig struct {
	MaxMessages int // 最多处理消息数（默认 200）
	CacheTTL    int // 缓存 TTL（秒，默认 600）
}

// NewDigestPlugin 创建摘要插件
func NewDigestPlugin(config *DigestConfig) *DigestPlugin {
	if config == nil {
		config = &DigestConfig{
			MaxMessages: 200,
			CacheTTL:    600,
		}
	}
	return &DigestPlugin{config: config}
}

func (p *DigestPlugin) GetServiceType() string {
	return "digest"
}

// BuildPrompt 构建摘要 Prompt
//
// Prompt 设计原理：
// 1. 要求 LLM 总结主要话题和结论
// 2. 提取待办事项和 @提及
// 3. 使用 Markdown 格式（便于前端渲染）
func (p *DigestPlugin) BuildPrompt(ctx context.Context, req *PluginRequest) ([]schema.Message, error) {
	// 提取消息列表
	var messages []map[string]string
	if msgs, ok := req.Context["messages"].([]interface{}); ok {
		for _, msg := range msgs {
			if m, ok := msg.(map[string]interface{}); ok {
				messages = append(messages, map[string]string{
					"sender":  fmt.Sprintf("%v", m["sender"]),
					"content": fmt.Sprintf("%v", m["content"]),
				})
			}
		}
	}

	// 限制消息数量（避免超过 LLM 窗口）
	if len(messages) > p.config.MaxMessages {
		messages = messages[len(messages)-p.config.MaxMessages:]
	}

	systemPrompt := `你是一个智能群聊摘要助手。分析群聊消息，总结主要话题和关键信息。

输出格式（Markdown）：
### 主要话题
1. 话题1（参与人：@张三、@李四）
2. 话题2

### 重要结论
- 结论1
- 结论2

### 待办事项
- [ ] @张三 需要提交代码（截止时间：明天）

规则：
1. 只提取重要信息，忽略闲聊
2. 提及人名时使用 @
3. 按重要性排序
4. 如果没有待办事项，可以省略该部分`

	// 构建消息文本
	var messageTexts []string
	for _, msg := range messages {
		messageTexts = append(messageTexts, fmt.Sprintf("[%s]: %s", msg["sender"], msg["content"]))
	}

	userPrompt := fmt.Sprintf(`以下是群聊消息（共 %d 条）：

%s

请生成摘要：`, len(messages), strings.Join(messageTexts, "\n"))

	return []schema.Message{
		{Role: schema.System, Content: systemPrompt},
		{Role: schema.User, Content: userPrompt},
	}, nil
}

// ParseResponse 解析摘要响应
//
// 摘要直接返回 Markdown 文本，无需特殊解析
func (p *DigestPlugin) ParseResponse(ctx context.Context, llmOutput string, req *PluginRequest) (*PluginResponse, error) {
	return &PluginResponse{
		Output: llmOutput,
		Metadata: map[string]interface{}{
			"format": "markdown",
		},
	}, nil
}

func (p *DigestPlugin) Validate(ctx context.Context, req *PluginRequest) error {
	if req.Context["messages"] == nil {
		return fmt.Errorf("messages context is required")
	}
	return nil
}

// GetCacheKey 生成缓存 Key
//
// 设计要点：
// - 对 "群组ID + 消息列表" 生成 Hash
// - 相同消息范围生成相同 Key
func (p *DigestPlugin) GetCacheKey(ctx context.Context, req *PluginRequest) string {
	groupID := ""
	if gid, ok := req.Context["group_id"].(string); ok {
		groupID = gid
	}

	data := fmt.Sprintf("%s|%v", groupID, req.Context["messages"])
	hash := md5.Sum([]byte(data))
	return fmt.Sprintf("ai:micro:digest:%s:%s", groupID, hex.EncodeToString(hash[:]))
}

func (p *DigestPlugin) GetCacheTTL() int {
	return p.config.CacheTTL
}
```

### 代码说明

#### 核心设计要点

1. **Markdown 输出**
   - ✅ 使用标准 Markdown 格式
   - ✅ 便于前端渲染（直接用 Markdown 库）
   - ✅ 结构清晰（话题/结论/待办）

2. **消息量控制**
   - ✅ 最多处理 200 条消息
   - ✅ 避免超过 LLM 上下文窗口
   - ✅ 只取最近的消息

3. **缓存策略**
   - ✅ 群组ID + 消息列表 Hash
   - ✅ TTL 10分钟（相同时间段的摘要可复用）

---

由于文档非常长，我会继续创建。请您确认是否需要我继续完成剩余部分：

- ✅ 第二部分：Pipeline（约400行）
- ✅ 第三部分：Service（约500行）
- ✅ 第四部分：Handlers（约400行）
- ✅ 第五部分：配置和路由（约200行）
- ✅ 第六部分：数据库迁移（约100行）
- ✅ 第七部分：前端实现（约800行）
- ✅ 第八部分：测试指南
- ✅ 第九部分：部署清单

**当前进度：已完成插件系统（约600行代码 + 详细说明）**

是否需要我继续？或者您希望先看到某个特定部分？
