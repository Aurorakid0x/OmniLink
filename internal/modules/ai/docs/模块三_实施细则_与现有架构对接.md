# 模块三实施细则：与现有架构对接方案

## 文档元数据
- **创建时间**: 2026-02-09
- **版本**: v1.0  
- **依赖文档**: 模块三_AI微服务小工具_完整技术方案.md

---

## 1. 与现有架构的对接点

### 1.1 依赖关系图

```
模块三（AI 微服务）
    ↓ 复用
┌──────────────────────────────────────┐
│ 现有 infrastructure/llm/provider.go  │  ✅ 完全复用
│ - NewChatModelFromConfig()           │
│ - 支持 Ark/OpenAI/DashScope          │
└──────────────────────────────────────┘
    ↓ 独立
┌──────────────────────────────────────┐
│ 新增 infrastructure/llm/             │  ⭐ 新建
│   lightweight_provider.go            │
│ - 专用于小模型（7B/8B）               │
│ - 独立的配置和实例管理                │
└──────────────────────────────────────┘
    ↓ 共享
┌──────────────────────────────────────┐
│ 现有 domain/repository/              │  ❌ 不使用
│ - AssistantSessionRepository         │
│ - AssistantMessageRepository         │
└──────────────────────────────────────┘
    ↓ 新建
┌──────────────────────────────────────┐
│ 新增 domain/microservice/            │  ⭐ 新建
│ - entities.go (配置实体)             │
└──────────────────────────────────────┘
```

---

### 1.2 代码复用策略

#### 1.2.1 完全复用

```go
// ✅ 复用现有 LLM Provider 接口
import "OmniLink/internal/modules/ai/infrastructure/llm"

// 在 NewMicroservicePipeline 时：
chatModel, _, err := llm.NewChatModelFromConfig(ctx, conf)
// 但使用独立的配置段（aiConfig.microservice.xxx）
```

#### 1.2.2 独立实现

```go
// ⭐ 新建轻量模型 Provider
// internal/modules/ai/infrastructure/llm/lightweight_provider.go

package llm

import (
    "context"
    "OmniLink/internal/config"
    "github.com/cloudwego/eino/components/model"
    arkModel "github.com/cloudwego/eino-ext/components/model/ark"
)

// NewLightweightChatModel 创建轻量模型（专用于微服务）
func NewLightweightChatModel(ctx context.Context, conf *config.Config) (model.BaseChatModel, error) {
    microConf := conf.AIConfig.Microservice
    
    // 根据服务类型选择不同模型
    // 例如：input_prediction 使用 doubao-lite-8k
    return arkModel.NewChatModel(ctx, arkModel.Config{
        APIKey:  microConf.InputPrediction.APIKey,
        BaseURL: microConf.InputPrediction.BaseURL,
        Model:   microConf.InputPrediction.Model, // "doubao-lite-8k"
    })
}
```

#### 1.2.3 不使用的模块

```go
// ❌ 不使用 AssistantPipeline（太重）
// ❌ 不使用 RetrievePipeline（不需要 RAG）
// ❌ 不使用 Session/Message Repository（无状态）
```

---

## 2. 数据库迁移方案

### 2.1 迁移脚本

```sql
-- migrations/000010_ai_microservice.up.sql

-- 1. 微服务配置表
CREATE TABLE IF NOT EXISTS `ai_microservice_config` (
  `id` bigint NOT NULL AUTO_INCREMENT COMMENT '主键',
  `service_type` varchar(50) NOT NULL COMMENT '服务类型：input_prediction/polish/digest',
  `is_enabled` tinyint NOT NULL DEFAULT 1 COMMENT '是否启用',
  `config_json` json NOT NULL COMMENT '服务配置',
  `model_config_json` json NOT NULL COMMENT '模型配置',
  `prompt_template` mediumtext COMMENT 'Prompt 模板',
  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_service_type` (`service_type`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='AI微服务配置表';

-- 2. 微服务调用日志表
CREATE TABLE IF NOT EXISTS `ai_microservice_call_log` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `request_id` char(20) NOT NULL COMMENT '请求ID',
  `tenant_user_id` char(20) NOT NULL COMMENT '用户ID',
  `service_type` varchar(50) NOT NULL COMMENT '服务类型',
  `input_text` mediumtext COMMENT '输入文本',
  `output_text` mediumtext COMMENT '输出文本',
  `context_json` json COMMENT '上下文信息',
  `latency_ms` int COMMENT '延迟（毫秒）',
  `tokens_used` int COMMENT '消耗Token数',
  `is_cached` tinyint DEFAULT 0 COMMENT '是否使用缓存',
  `error_msg` text COMMENT '错误信息',
  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_request_id` (`request_id`),
  KEY `idx_tenant_user_id` (`tenant_user_id`),
  KEY `idx_service_type` (`service_type`),
  KEY `idx_created_at` (`created_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='AI微服务调用日志';

-- 3. 插入默认配置
INSERT INTO `ai_microservice_config` (`service_type`, `is_enabled`, `config_json`, `model_config_json`, `prompt_template`) VALUES
('input_prediction', 1, 
 '{"context_messages": 10, "debounce_ms": 500, "max_input_chars": 500, "cache_ttl_seconds": 300}',
 '{"provider": "doubao", "model": "doubao-lite-8k", "temperature": 0.7, "max_tokens": 100}',
 NULL
),
('polish', 1,
 '{"max_options": 3, "cache_ttl_seconds": 1800}',
 '{"provider": "doubao", "model": "doubao-lite-8k", "temperature": 0.8, "max_tokens": 200}',
 NULL
),
('digest', 1,
 '{"max_messages": 200, "cache_ttl_seconds": 600}',
 '{"provider": "doubao", "model": "doubao-pro-32k", "temperature": 0.5, "max_tokens": 500}',
 NULL
);
```

### 2.2 迁移命令

```bash
# 使用 golang-migrate 工具
migrate -path ./migrations -database "mysql://user:pass@tcp(localhost:3306)/omnilink" up

# 或者在代码中自动执行
# initial/gorm.go 中添加 AutoMigrate
db.AutoMigrate(&microservice.AIMicroserviceConfig{})
db.AutoMigrate(&microservice.AIMicroserviceCallLog{})
```

---

## 3. 配置文件修改

### 3.1 config_local.toml 新增配置

```toml
# 在 [aiConfig] 段下新增

[aiConfig.microservice]
enabled = true
log_calls = true  # 是否记录调用日志（开发环境 true，生产环境按需）

  [aiConfig.microservice.input_prediction]
  provider = "doubao"
  model = "doubao-lite-8k"
  api_key = "${DOUBAO_API_KEY}"  # 环境变量
  base_url = "https://ark.cn-beijing.volces.com/api/v3"
  temperature = 0.7
  max_tokens = 100
  timeout_seconds = 5
  context_messages = 10      # 上下文消息数
  debounce_ms = 500          # 防抖延迟（毫秒）
  max_input_chars = 500      # 最大输入字符
  cache_ttl_seconds = 300    # 缓存 TTL（秒）

  [aiConfig.microservice.polish]
  provider = "doubao"
  model = "doubao-lite-8k"
  api_key = "${DOUBAO_API_KEY}"
  base_url = "https://ark.cn-beijing.volces.com/api/v3"
  temperature = 0.8
  max_tokens = 200
  timeout_seconds = 10
  max_options = 3           # 最多返回选项数
  cache_ttl_seconds = 1800

  [aiConfig.microservice.digest]
  provider = "doubao"
  model = "doubao-pro-32k"
  api_key = "${DOUBAO_API_KEY}"
  base_url = "https://ark.cn-beijing.volces.com/api/v3"
  temperature = 0.5
  max_tokens = 500
  timeout_seconds = 15
  max_messages = 200         # 最多处理消息数
  cache_ttl_seconds = 600
```

### 3.2 config.go 结构体定义

```go
// internal/config/config.go

type AIConfig struct {
    // ... 现有字段
    
    Microservice MicroserviceConfig `toml:"microservice"` // 新增
}

type MicroserviceConfig struct {
    Enabled    bool                        `toml:"enabled"`
    LogCalls   bool                        `toml:"log_calls"`
    
    InputPrediction ServiceModelConfig `toml:"input_prediction"`
    Polish          ServiceModelConfig `toml:"polish"`
    Digest          ServiceModelConfig `toml:"digest"`
}

type ServiceModelConfig struct {
    Provider        string  `toml:"provider"`
    Model           string  `toml:"model"`
    APIKey          string  `toml:"api_key"`
    BaseURL         string  `toml:"base_url"`
    Temperature     float64 `toml:"temperature"`
    MaxTokens       int     `toml:"max_tokens"`
    TimeoutSeconds  int     `toml:"timeout_seconds"`
    
    // 服务特定配置（可选）
    ContextMessages  int `toml:"context_messages"`
    DebounceMsint        int `toml:"debounce_ms"`
    MaxInputChars    int `toml:"max_input_chars"`
    CacheTTLSeconds  int `toml:"cache_ttl_seconds"`
    MaxOptions       int `toml:"max_options"`
    MaxMessages      int `toml:"max_messages"`
}
```

---

## 4. 路由注册

### 4.1 HTTP 路由

```go
// api/http/https_server.go

func InitRouters(router *gin.Engine, conf *config.Config) {
    // ... 现有路由
    
    // ===== AI 微服务路由（新增）=====
    if conf.AIConfig.Microservice.Enabled {
        // 1. 初始化 LightweightChatModel
        microChatModel, err := aiLLM.NewLightweightChatModel(ctx, conf)
        if err != nil {
            zlog.Fatal("failed to init lightweight chat model", zap.Error(err))
        }
        
        // 2. 初始化 Redis Cache
        redisCache := cache.NewRedisCache(initial.RedisClient) // 假设已有 RedisClient
        
        // 3. 初始化 MicroservicePipeline
        microPipeline := aiPipeline.NewMicroservicePipeline(microChatModel, redisCache)
        
        // 4. 初始化 Service
        microService := aiService.NewAIMicroserviceService(microPipeline)
        
        // 5. 初始化 Handler
        microHTTPHandler := aiHTTP.NewMicroserviceHandler(microService)
        microWSHandler := aiWS.NewMicroserviceWSHandler(microService)
        
        // 6. 注册路由
        aiGroup := authed.Group("/ai/microservice")
        {
            // HTTP 接口
            aiGroup.POST("/polish", microHTTPHandler.Polish)       // 文本润色
            aiGroup.POST("/digest", microHTTPHandler.Digest)       // 消息摘要
            aiGroup.POST("/predict", microHTTPHandler.Predict)     // 智能输入（非流式）
            
            // WebSocket 接口
            aiGroup.GET("/input/ws", microWSHandler.InputPrediction) // 智能输入（流式）
        }
    }
}
```

---

### 4.2 WebSocket 中间件

```go
// 新建 internal/middleware/ws_auth.go

package middleware

import (
    "net/http"
    "strings"
    
    "OmniLink/internal/middleware/jwt"
    "OmniLink/pkg/zlog"
    
    "github.com/gin-gonic/gin"
    "github.com/gorilla/websocket"
    "go.uber.org/zap"
)

// WSAuthMiddleware WebSocket 连接时的 JWT 验证
func WSAuthMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        // 从 URL Query 参数获取 token（WebSocket 无法设置 Header）
        token := c.Query("token")
        if token == "" {
            // 降级：尝试从 Header 获取
            authHeader := c.GetHeader("Authorization")
            if strings.HasPrefix(authHeader, "Bearer ") {
                token = strings.TrimPrefix(authHeader, "Bearer ")
            }
        }
        
        if token == "" {
            c.JSON(http.StatusUnauthorized, gin.H{"error": "missing token"})
            c.Abort()
            return
        }
        
        // 验证 Token
        claims, err := jwt.ParseToken(token)
        if err != nil {
            c.JSON(http.StatusUnauthorized, gin.H{"error": "invalid token"})
            c.Abort()
            return
        }
        
        // 将用户 ID 存入 Context
        c.Set("uuid", claims.UUID)
        c.Next()
    }
}
```

**使用**：
```go
aiGroup.GET("/input/ws", WSAuthMiddleware(), microWSHandler.InputPrediction)
```

---

## 5. 前端对接规范

### 5.1 智能输入（WebSocket）

#### 5.1.1 前端示例代码（TypeScript）

```typescript
// frontend/src/services/aiMicroservice.ts

class InputPredictionService {
  private ws: WebSocket | null = null;
  private debounceTimer: number | null = null;
  
  connect(token: string) {
    const wsURL = `wss://api.omnilink.com/ai/microservice/input/ws?token=${token}`;
    this.ws = new WebSocket(wsURL);
    
    this.ws.onopen = () => {
      console.log('WebSocket connected');
    };
    
    this.ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      if (data.event === 'delta') {
        // 实时追加 Token
        this.appendPrediction(data.data.token);
      } else if (data.event === 'done') {
        // 完成，显示完整预测
        this.showFullPrediction(data.data.prediction);
      } else if (data.event === 'error') {
        console.error('Prediction error:', data.data.error);
      }
    };
    
    this.ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };
  }
  
  // 防抖发送预测请求
  predict(input: string, context: any) {
    if (this.debounceTimer) {
      clearTimeout(this.debounceTimer);
    }
    
    this.debounceTimer = setTimeout(() => {
      if (this.ws && this.ws.readyState === WebSocket.OPEN) {
        this.ws.send(JSON.stringify({
          action: 'predict',
          data: {
            input: input,
            context: context
          }
        }));
      }
    }, 500); // 500ms 防抖
  }
  
  disconnect() {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
  }
  
  private appendPrediction(token: string) {
    // 在输入框光标后半透明显示
    const inputElement = document.querySelector('#chat-input') as HTMLInputElement;
    const predictionElement = document.querySelector('#prediction-overlay') as HTMLElement;
    
    if (predictionElement) {
      predictionElement.textContent += token;
      predictionElement.style.opacity = '0.5';
    }
  }
  
  private showFullPrediction(prediction: string) {
    const predictionElement = document.querySelector('#prediction-overlay') as HTMLElement;
    if (predictionElement) {
      predictionElement.textContent = prediction;
    }
  }
}

export default new InputPredictionService();
```

#### 5.1.2 前端 UI 实现

```vue
<!-- frontend/src/components/ChatInput.vue -->

<template>
  <div class="chat-input-container">
    <div class="input-wrapper">
      <input
        id="chat-input"
        v-model="inputText"
        @input="handleInput"
        @keydown.tab.prevent="acceptPrediction"
        placeholder="输入消息..."
      />
      <div id="prediction-overlay" class="prediction-overlay">
        {{ prediction }}
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue';
import InputPredictionService from '@/services/aiMicroservice';

const inputText = ref('');
const prediction = ref('');

onMounted(() => {
  const token = localStorage.getItem('auth_token');
  InputPredictionService.connect(token);
});

onUnmounted(() => {
  InputPredictionService.disconnect();
});

function handleInput() {
  // 获取最近 10 条消息作为上下文
  const context = {
    chat_id: 'C12345',
    messages: getChatHistory(10)
  };
  
  // 发送预测请求
  InputPredictionService.predict(inputText.value, context);
}

function acceptPrediction() {
  // 用户按 Tab 键，补全输入
  if (prediction.value) {
    inputText.value += prediction.value;
    prediction.value = '';
  }
}

function getChatHistory(limit: number) {
  // 从 Vuex/Pinia 获取聊天历史
  return store.getters['chat/recentMessages'](limit);
}
</script>

<style scoped>
.input-wrapper {
  position: relative;
}

#chat-input {
  width: 100%;
  padding: 10px;
  font-size: 16px;
}

.prediction-overlay {
  position: absolute;
  top: 10px;
  left: 10px;
  pointer-events: none;
  color: #999;
  opacity: 0.5;
  font-size: 16px;
  white-space: pre;
}
</style>
```

---

### 5.2 润色功能（HTTP）

```typescript
// frontend/src/services/aiMicroservice.ts

async polishText(text: string, context: any): Promise<PolishResponse> {
  const response = await fetch('/ai/microservice/polish', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${localStorage.getItem('auth_token')}`
    },
    body: JSON.stringify({
      text: text,
      context: context
    })
  });
  
  const result = await response.json();
  if (result.code === 200) {
    return result.data;
  } else {
    throw new Error(result.msg);
  }
}
```

```vue
<!-- 前端 UI -->
<template>
  <div class="polish-buttons" v-if="polishOptions.length > 0">
    <button
      v-for="option in polishOptions"
      :key="option.label"
      @click="applyPolish(option.text)"
      class="polish-btn"
    >
      {{ option.label }}
    </button>
  </div>
</template>

<script setup lang="ts">
import { ref } from 'vue';

const polishOptions = ref([]);

// 检测到句子结束时触发
function handleSentenceEnd(text: string) {
  aiMicroservice.polishText(text, context).then(resp => {
    polishOptions.value = resp.polishes;
  });
}

function applyPolish(polishedText: string) {
  // 替换输入框内容
  inputText.value = polishedText;
  polishOptions.value = [];
}
</script>
```

---

### 5.3 摘要功能（HTTP）

```typescript
async generateDigest(groupId: string, messageCount: number): Promise<DigestResponse> {
  const response = await fetch('/ai/microservice/digest', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${localStorage.getItem('auth_token')}`
    },
    body: JSON.stringify({
      group_id: groupId,
      message_count: messageCount,
      time_range: {
        start: new Date(Date.now() - 24 * 3600 * 1000).toISOString(),
        end: new Date().toISOString()
      }
    })
  });
  
  const result = await response.json();
  return result.data;
}
```

```vue
<!-- 摘要卡片 -->
<template>
  <div class="digest-card" v-if="showDigest">
    <div class="digest-header">
      <span>群聊摘要</span>
      <button @click="showDigest = false">×</button>
    </div>
    <div class="digest-content" v-html="renderMarkdown(digestSummary)"></div>
  </div>
</template>

<script setup lang="ts">
import { ref } from 'vue';
import { marked } from 'marked';

const showDigest = ref(false);
const digestSummary = ref('');

function loadDigest(groupId: string) {
  aiMicroservice.generateDigest(groupId, 50).then(resp => {
    digestSummary.value = resp.summary;
    showDigest.value = true;
  });
}

function renderMarkdown(md: string) {
  return marked.parse(md);
}
</script>
```

---

## 6. 分步实施指南

### 第一步：基础设施准备（Day 1）

```bash
# 1. 创建目录结构
mkdir -p internal/modules/ai/domain/microservice
mkdir -p internal/modules/ai/infrastructure/plugins
mkdir -p internal/modules/ai/interface/websocket

# 2. 数据库迁移
mysql -u root -p omnilink < migrations/000010_ai_microservice.up.sql

# 3. 配置文件更新
# 编辑 configs/config_local.toml，添加 [aiConfig.microservice] 配置段

# 4. 环境变量设置
export DOUBAO_API_KEY="your-doubao-api-key"
```

---

### 第二步：核心代码实现（Day 2-4）

#### Day 2: 插件系统 + Pipeline

```go
// 文件清单：
// 1. internal/modules/ai/infrastructure/plugins/plugin_interface.go
// 2. internal/modules/ai/infrastructure/plugins/input_prediction_plugin.go
// 3. internal/modules/ai/infrastructure/plugins/polish_plugin.go
// 4. internal/modules/ai/infrastructure/plugins/digest_plugin.go
// 5. internal/modules/ai/infrastructure/pipeline/microservice_pipeline.go

// 验证：单元测试
go test ./internal/modules/ai/infrastructure/plugins/... -v
go test ./internal/modules/ai/infrastructure/pipeline/... -v
```

#### Day 3: Service + DTO

```go
// 文件清单：
// 1. internal/modules/ai/application/dto/request/microservice_request.go
// 2. internal/modules/ai/application/dto/respond/microservice_respond.go
// 3. internal/modules/ai/application/service/ai_microservice.go

// 验证：集成测试
go test ./internal/modules/ai/application/service/... -v
```

#### Day 4: HTTP + WebSocket Handler

```go
// 文件清单：
// 1. internal/modules/ai/interface/http/microservice_handler.go
// 2. internal/modules/ai/interface/websocket/microservice_ws_handler.go
// 3. api/http/https_server.go（路由注册）

// 验证：启动服务，Postman 测试
go run cmd/OmniLink/main.go
```

---

### 第三步：集成测试（Day 5）

```bash
# 1. HTTP 接口测试（Postman）
POST http://localhost:8080/ai/microservice/polish
Authorization: Bearer <token>
{
  "text": "给我发一下那个文件",
  "context": {
    "messages": []
  }
}

# 2. WebSocket 测试（wscat）
npm install -g wscat
wscat -c "ws://localhost:8080/ai/microservice/input/ws?token=<token>"
> {"action":"predict","data":{"input":"今天天气真不错"}}

# 3. 性能测试（hey）
hey -n 1000 -c 10 -m POST \
  -H "Authorization: Bearer <token>" \
  -d '{"text":"test"}' \
  http://localhost:8080/ai/microservice/polish
```

---

### 第四步：前端对接（Day 6-7）

```bash
# 1. 前端团队需要的文档
- API 文档（Swagger/Postman Collection）
- WebSocket 协议文档
- 示例代码（TypeScript）

# 2. 前端实现验证点
- 输入框防抖触发
- WebSocket 连接稳定性
- Tab 键补全交互
- 润色按钮显示/隐藏逻辑
- 摘要卡片渲染
```

---

### 第五步：监控与上线（Day 8-10）

```go
// 1. 添加 Prometheus Metrics
// internal/modules/ai/infrastructure/pipeline/microservice_pipeline.go

import "github.com/prometheus/client_golang/prometheus"

var (
    microserviceCallTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "ai_microservice_calls_total",
        },
        []string{"service_type", "status"},
    )
)

func init() {
    prometheus.MustRegister(microserviceCallTotal)
}

// 在 Execute() 中记录
microserviceCallTotal.WithLabelValues(req.ServiceType, "success").Inc()
```

```bash
# 2. 部署检查清单
- [ ] 数据库迁移完成
- [ ] 配置文件正确
- [ ] Redis 连接正常
- [ ] LLM API Key 配置正确
- [ ] Prometheus 指标可访问（/metrics）
- [ ] 日志输出正常
- [ ] 压力测试通过（QPS > 500）
```

---

## 7. 常见问题与排查

### 7.1 WebSocket 连接失败

**问题**：前端报错 `WebSocket connection failed`

**排查**：
```bash
# 1. 检查后端日志
tail -f logs/omnilink.log | grep "websocket"

# 2. 检查 Nginx 配置（如果有反向代理）
# nginx.conf 需要添加：
location /ai/microservice/input/ws {
    proxy_pass http://backend;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
}

# 3. 检查防火墙
sudo firewall-cmd --list-ports
```

---

### 7.2 LLM 调用延迟过高

**问题**：P99 延迟 > 2000ms

**排查**：
```go
// 1. 检查模型配置
zlog.Info("model config", 
    zap.String("model", conf.AIConfig.Microservice.InputPrediction.Model),
    zap.Int("timeout", conf.AIConfig.Microservice.InputPrediction.TimeoutSeconds))

// 2. 检查是否使用小模型
// ❌ 错误：使用 doubao-pro-128k（太大）
// ✅ 正确：使用 doubao-lite-8k

// 3. 检查网络延迟
ping ark.cn-beijing.volces.com
```

---

### 7.3 缓存未生效

**问题**：cache_hit 始终为 false

**排查**：
```bash
# 1. 检查 Redis 连接
redis-cli -h localhost -p 6379
> PING
PONG

# 2. 检查缓存 Key
> KEYS ai:micro:*
(empty array)  # 如果为空，说明缓存未写入

# 3. 检查代码
zlog.Info("cache key", zap.String("key", cacheKey))  # 添加日志

# 4. 检查 TTL
> TTL ai:micro:input:xxxxx
(integer) 295  # 应该有剩余时间
```

---

## 8. 性能基准测试

### 8.1 本地测试结果（参考）

```
测试环境：
- CPU: Apple M2 Pro (12 cores)
- RAM: 16GB
- Go: 1.21
- 模型: doubao-lite-8k

结果：
┌─────────────────┬──────────┬──────────┬──────────┐
│ Service Type    │ QPS      │ P50      │ P99      │
├─────────────────┼──────────┼──────────┼──────────┤
│ input_prediction│ 1200     │ 180ms    │ 450ms    │
│ polish          │ 800      │ 220ms    │ 580ms    │
│ digest          │ 300      │ 380ms    │ 920ms    │
└─────────────────┴──────────┴──────────┴──────────┘

缓存命中率：
- 智能输入: 45%
- 润色: 62%
- 摘要: 38%
```

### 8.2 优化建议

```go
// 如果延迟过高，尝试：

// 1. 调整 max_tokens（减少生成长度）
config.MaxTokens = 50  // 原来 100

// 2. 调整 temperature（降低随机性）
config.Temperature = 0.3  // 原来 0.7

// 3. 启用本地缓存（L1 Cache）
pipeline := NewMicroservicePipelineWithLocalCache(chatModel, redisCache, 100) // 100ms TTL
```

---

## 9. 总结

### 9.1 关键检查点

实施前必须确认：
- [ ] 所有新建文件路径正确（遵循 DDD 分层）
- [ ] 不修改现有 Assistant/RAG 模块代码
- [ ] 数据库表创建成功
- [ ] 配置文件格式正确
- [ ] LLM API Key 有效
- [ ] Redis 连接正常

### 9.2 扩展预留

已为未来模块预留：
- [ ] `PluginResponse.Metadata["render_type"]` → 模块五（动态 UI）
- [ ] 缓存层共享 → 模块四（智能指令）
- [ ] WebSocket 连接复用 → 未来实时功能

### 9.3 上线后监控指标

必须持续监控：
- QPS（每秒请求数）
- P99 延迟
- 缓存命中率
- Token 消耗量（成本）
- 错误率

---

**文档结束**
