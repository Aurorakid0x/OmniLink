完整修改方案（不写具体代码）
你这次的目标是：把现有“单个大 ingestNode”重构为 Eino Graph 的多节点编排，并且让 Merge/Chunk/Embed/Upsert/StatusUpdate 都成为可独立替换的节点，符合 ai prd.md 的“Transformer/Chunker 可替换、后期不回头删改”原则，以及 ai模块架构.md 的分层。

A. 总体结构（Graph 的“状态流”设计）
核心做法：引入一个流水线内部状态对象（例如 IngestState，放在 pipeline/ingest_pipeline.go 内部即可），Graph 的节点都只接收/返回这个状态对象。

状态对象建议包含：

Req：原始 IngestRequest（tenant、source、messages…）
KBID/SourceID：已确保的知识库与数据源 ID
Docs：[]*schema.Document（从 MergeTurns 开始都用 Document 传递）
VectorIDsAttempted：本批次准备 upsert 的 vector_id 列表
Stats：chunks/ok/skip/fail 等统计
Err：允许节点把“业务错误”写进 state，而不是直接 return error（用于保证 StatusUpdate 一定执行）
这样做的原因：Eino 的 indexer 节点输出通常不是“文档”，而是“IDs”，并且一旦某节点直接返回 error，后续节点可能不执行。用 state.Err 可以做到：

Upsert 失败时仍然跑 StatusUpdate，把本批次向量状态写回 MySQL；
最终 Ingest() 仍然把错误返回给上层（HTTP 回填也能看到失败统计 + 错误信息）。
B. 节点拆分与职责（你指定的五类节点）
下面按你指定的节点名给出清晰的职责边界，并补齐必须做的幂等/多租户/观测点。

0) Prepare（前置节点，必需但不在你列的五个里）
职责：

校验 tenant_user_id/source_type/source_key 等必填；
repo.EnsureKnowledgeBase/EnsureKnowledgeSource 得到 KBID/SourceID；
初始化 state、计时、统一日志字段（tenant/source/session）。
这是把“写 MySQL 的 KB/Source Upsert”从 Chunk/StatusUpdate 里剥离出来，避免后续重用 pipeline 时重复做这些逻辑。

1) MergeTurns 节点（Transformer）
目标：把 []chat.entity.Message 聚合成语义段落（segments）。

落点建议：

直接把 chat_turn_merger.go 从“工具函数”升级为一个 Eino 风格的 transformer（对外暴露 Transform(ctx, docs) 或者被节点封装调用）。
这个节点输入仍然来自 state.Req.Messages，输出写入 state.Docs（每个 segment 一个 Document）。
关键点：

排序与时间窗逻辑保持现有行为（按 session 分组 + 5 分钟窗口），确保可重复；
Document 的 Content 存 segment 文本；
Document 的 MetaData 至少带：tenant_user_id/kb_id/source_type/source_key/session_uuid/session_type/session_name/segment_index（后续做 trace、过滤、定位问题很重要）。
2) Chunk 节点（Transformer）
目标：把 segment 文本切成 chunk 文档，并在这一层完成 幂等与 MySQL 事实落库（chunk + vector_record）。

建议把 simple_chunker.go 改造成 Eino transformer 语义（输入 docs，输出被切分后的 docs）。同时在 Chunk 节点里（或紧挨着 Chunk 的子步骤里）做落库与幂等：

Chunk 节点输出的每个 chunk doc 必须具备：

doc.ID = vector_id（稳定可复现，作为 Milvus 主键）
meta["chunk_id"] = <mysql chunk id>
meta["tenant_user_id"/"kb_id"/"source_type"/"source_key"]（满足 milvus_eino.go 的约定）
meta["metadata"] = <string JSON>（将来检索引用、定位 session）
幂等策略落在这一层最合理，因为这就是“chunk 的事实定义层”：

对每个 chunk 生成稳定的 chunk_key（tenant + source + segment_index + chunk_index + content_hash 等）
查 repo.GetChunkByChunkKey：
存在且其 vector_record.embed_status == succeeded：本 chunk 直接 skip（计数 + 不进入后续 Embed/Upsert）
存在但 vector_record 不存在：补 CreateVectorRecord
存在且 vector_record pending/failed：复用已有 vector_id（或保证重算出的 vector_id 与已有一致）
不存在：CreateChunkAndVectorRecord 事务写入（保证 chunk_id 与 vector_record 对应）
这一层还要做“内容治理”：

内容截断（你现在是 truncate 4096 rune）；
metadata JSON 构造（把 session_uuid、chunk_index 等写进去）。
3) Embed 节点（Embedding）
目标：给 chunk docs 批量打向量。

做法建议：

不要再让 Embed 只是“字符串数组 -> 向量数组”的游离调用，而是让 Embed 节点把向量写回到 Document（doc.DenseVector()可取到）。
可实现为一个 Eino 节点：内部用你现有的 embedding.Embedder（mock 以及未来真实 provider）对 docs[i].Content 批量 embedding。
关键点：

强校验维度与配置一致（vectorDim），不一致要把该 doc 标记为失败：写入 state.Err 或在 doc.MetaData 写 error，再由 StatusUpdate 落库。
4) Upsert 节点（Indexer）
目标：把带向量的 docs 写入 Milvus。

这里强烈建议复用现有的 Eino 适配层：

milvus_eino.go 的 EinoVectorStore 已经实现了 indexer.Indexer.Store(ctx, docs)，并且对 metadata 做了强校验。
Upsert 节点只需要把当前 state.Docs 交给它 store（返回 ids）。
异常处理策略（保证 StatusUpdate 一定执行）：

Upsert 节点不要“直接 return error 导致图中断”；而是把错误写到 state.Err，并把“本次尝试 upsert 的 ids”写进 state.VectorIDsAttempted，让 StatusUpdate 去回写失败状态。
5) StatusUpdate 节点（回写状态 + 统计 + 观测）
目标：唯一的“最终一致性收口点”。

职责：

如果 state.Err != nil：对 state.VectorIDsAttempted 全部 UpdateVectorStatus(... failed, errMsg)（或对能精确定位失败的 subset 更新）
如果 Upsert 成功：对成功 ids UpdateVectorStatus(... succeeded, "")
汇总统计：chunks、ok/skip/fail、耗时；打结构化日志（tenant/source/session）
注意：由于 Chunk 层已经把 skip 的 chunk 从 docs 里剔除了，所以：

VectorsSkip 在 Chunk 节点就能精确累计；
VectorsOK/Fail 在 StatusUpdate 收口。
C. 文件级改动范围（只列方案，不写代码）
你要求“一次性重构现有调用”，这意味着要改的不止 pipeline：

重点重构：internal/modules/ai/infrastructure/pipeline/ingest_pipeline.go
把现在的单节点 ingestNode 改为 Graph 多节点；
引入 IngestState（仅 pipeline 内部使用）；
NewIngestPipeline(...) 变为构建并 compile graph；
Ingest(ctx, req) 仍可保留对外签名不变（让上层 service/handler 不需要大改），但内部走 runnable。
Transformer 形态升级：
internal/modules/ai/infrastructure/transform/chat_turn_merger.go
从“Merge(messages) []string”转成“可作为节点调用的 transformer 语义”（具体是实现 Eino 的 document transformer，还是被节点包装调用，由你定；方案上倾向“实现 transformer”，便于真正 AddDocumentTransformerNode）。
internal/modules/ai/infrastructure/chunking/simple_chunker.go
从“Chunk(text) []string”改为“对 Document 进行切分的 transformer”。
Wiring 调整：
api/http/https_server.go
构造的对象从 *ChatTurnMerger + *SimpleChunker（老语义）改为 “Transformer 语义”；
Pipeline 构造参数也随之变更（传入 transformers/indexer/embedder/repo）。
其他文件通常不需要改：
ingest_service.go、admin_handler.go 逻辑可不动（除非你想把统计口径更细化）。
vectordb/milvus_eino.go 大概率不改，只要你保证写入 doc.MetaData 的 key 与它的约定一致（tenant_user_id、kb_id、source_type、source_key、chunk_id、metadata）。
D. 验收与回归（保证这次重构“真有价值”）
行为一致性（最重要）
同样的 backfill 请求，MySQL 的 chunk/vector_record 仍可落库；
Milvus collection 中 tenant_user_id 过滤能查到数据；
回填返回的统计字段仍然正确、可解释（ok/skip/fail）。
幂等回归
连续跑两次同一 user 的 backfill：
第一次 vectors_ok 增长；
第二次 vectors_skip 明显增长、vectors_ok 接近 0（除非中间你插入了新消息）。
故障回归
人为让 milvus 不可用/Upsert 报错：
pipeline 返回 error；
MySQL 的 ai_vector_record.embed_status 被回写为 failed，error_msg 有值。